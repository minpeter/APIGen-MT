{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37fa6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional, Annotated, Callable, Tuple\n",
    "from difflib import SequenceMatcher # Option 1 for basic similarity\n",
    "import heapq # For finding top N similar items efficiently\n",
    "import numpy as np # For calculating mean similarity\n",
    "from rouge_score import rouge_scorer\n",
    "from openai import OpenAI, APIError\n",
    "from function_schema import get_function_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787e83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Friendli AI Client Setup ---\n",
    "token = os.getenv(\"FRIENDLI_TOKEN\")\n",
    "if not token:\n",
    "    print(\"Error: FRIENDLI_TOKEN environment variable not set.\")\n",
    "    print(\"Please set the environment variable or replace '<YOUR_FRIENDLI_TOKEN>' in the code.\")\n",
    "    token = \"<YOUR_FRIENDLI_TOKEN>\" # Placeholder\n",
    "\n",
    "if token == \"<YOUR_FRIENDLI_TOKEN>\":\n",
    "     print(\"Warning: Using placeholder Friendli token. LLM calls will likely fail.\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"https://api.friendli.ai/serverless/v1\",\n",
    "    api_key = token\n",
    ")\n",
    "LLM_MODEL_NAME = \"deepseek-r1\" # Specify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888b0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(\n",
    "    city: Annotated[str, \"The city to get the weather for\"],\n",
    "    unit: Annotated[Optional[str], \"The unit to return the temperature in\"] = \"celcius\",\n",
    ") -> str:\n",
    "    \"\"\"Returns the weather for the given city.\"\"\"\n",
    "    return f\"Weather for {city} is 20°C\"\n",
    "\n",
    "def get_news(\n",
    "    topic: Annotated[str, \"The topic to get news for\"],\n",
    "    source: Annotated[Optional[str], \"The source to get news from\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Returns the news for the given topic.\"\"\"\n",
    "    return f\"News for {topic} from {source if source else 'all sources'}\"\n",
    "\n",
    "def get_current_location() -> str:\n",
    "    \"\"\"Returns the current location of the user.\"\"\"\n",
    "    return \"Current location is Seoul, South Korea\"\n",
    "\n",
    "tools = [\n",
    "    get_weather,\n",
    "    get_news,\n",
    "    get_current_location,\n",
    "]\n",
    "\n",
    "tool_schemas = [get_function_schema(tool) for tool in tools]\n",
    "tool_schemas_json = json.dumps(tool_schemas, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a39594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Annotated, Optional, List, Callable, Dict, Any\n",
    "\n",
    "# 도구 함수 정의\n",
    "\n",
    "def create_calendar_event(\n",
    "    summary: Annotated[str, \"Title of the event to be added (default: 'New Event')\"],\n",
    "    start_time: Annotated[str, \"Start date and time of the event (format: 'yyyy-MM-dd HH:mm')\"],\n",
    "    end_time: Annotated[str, \"End date and time of the event (format: 'yyyy-MM-dd HH:mm')\"]\n",
    ") -> None:\n",
    "    \"\"\"Creates a new calendar event.\"\"\"\n",
    "    # 내부 구현은 생략 (pass)\n",
    "    # 실제 구현 시에는 캘린더 API를 호출하여 이벤트를 생성합니다.\n",
    "    # 예: google_calendar.create_event(summary=summary, start=start_time, end=end_time)\n",
    "    pass\n",
    "\n",
    "def fetch_calendar_events(\n",
    "    start_date: Annotated[str, \"Start date of the search range (format: yyyy-MM-dd)\"],\n",
    "    end_date: Annotated[str, \"End date of the search range (format: yyyy-MM-dd)\"]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Retrieves calendar events within a specified date range.\n",
    "    Requires authorization first. If not authorized, should call authorize_calendar_access.\n",
    "    Returns a JSON string representing the events or an error message.\n",
    "    \"\"\"\n",
    "    # 내부 구현은 생략 (pass)\n",
    "    # 실제 구현 시에는 인증 상태 확인 후 캘린더 API를 호출합니다.\n",
    "    # is_authorized = check_auth()\n",
    "    # if not is_authorized:\n",
    "    #     return json.dumps({\"message\": \"You need to authorize the assistant to access your calendar.\"})\n",
    "    # try:\n",
    "    #     events = calendar_api.fetch_events(start_date, end_date)\n",
    "    #     return json.dumps(events)\n",
    "    # except Exception as e:\n",
    "    #     return json.dumps({\"message\": f\"Error fetching calendar events: {e}\"})\n",
    "    pass\n",
    "\n",
    "def authorize_calendar_access() -> None:\n",
    "    \"\"\"\n",
    "    Initiates the authorization process for calendar access.\n",
    "    Must be called first before using calendar-related tools like fetch_calendar_events or create_calendar_event if not already authorized.\n",
    "    \"\"\"\n",
    "    # 내부 구현은 생략 (pass)\n",
    "    # 실제 구현 시에는 OAuth 플로우 등을 시작하여 사용자 인증/인가를 받습니다.\n",
    "    # print(\"Please visit <authorization_url> to authorize calendar access.\")\n",
    "    pass\n",
    "\n",
    "def web_search(\n",
    "    query: Annotated[str, \"The query to search for on the web.\"]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Searches the web (DuckDuckGo) for the given query.\n",
    "    Returns a JSON string containing search results.\n",
    "    \"\"\"\n",
    "    # 내부 구현은 생략 (pass)\n",
    "    # 실제 구현 시에는 웹 검색 라이브러리나 API를 호출합니다.\n",
    "    # results = duckduckgo_search(query)\n",
    "    # return json.dumps(results)\n",
    "    pass\n",
    "\n",
    "\n",
    "tools = [\n",
    "    create_calendar_event,\n",
    "    fetch_calendar_events,\n",
    "    authorize_calendar_access,\n",
    "    web_search,\n",
    "]\n",
    "tool_schemas = [get_function_schema(tool) for tool in tools]\n",
    "tool_schemas_json = json.dumps(tool_schemas, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfced6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "QUERIES_FILENAME = \"diverse_queries_with_scores_v4.json\" # New filename for this version\n",
    "NUM_GENERATION_TURNS = 3\n",
    "QUERIES_TO_GENERATE_PER_TURN = 10\n",
    "REQUEST_BATCH_SIZE_PER_TURN = 15\n",
    "MAX_ATTEMPTS_PER_TURN = 5\n",
    "SIMILARITY_THRESHOLD = 0.8\n",
    "TOP_N_SIMILAR = 10 # Alpaca stores top 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe0d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_queries_with_scores(filename: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Loads previously generated query objects from a JSON file.\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, list) and all(isinstance(item, dict) and 'q' in item for item in data):\n",
    "                    print(f\"Loaded {len(data)} query objects from {filename}\")\n",
    "                    return data\n",
    "                else:\n",
    "                    print(f\"Warning: Invalid format found in {filename}. Starting fresh.\")\n",
    "                    return []\n",
    "        except (json.JSONDecodeError, IOError) as e:\n",
    "            print(f\"Error loading {filename}: {e}. Starting fresh.\")\n",
    "            return []\n",
    "    else:\n",
    "        print(f\"No existing query file found ({filename}). Starting fresh.\")\n",
    "        return []\n",
    "\n",
    "def save_queries_with_scores(query_objects: List[Dict[str, Any]], filename: str):\n",
    "    \"\"\"Saves the list of query objects to a JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            # Use indent=4 like Alpaca's output\n",
    "            json.dump(query_objects, f, indent=4, ensure_ascii=False)\n",
    "        print(f\"Saved {len(query_objects)} query objects to {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error saving queries to {filename}: {e}\")\n",
    "\n",
    "def is_valid_query_line(q_text: str) -> bool:\n",
    "    \"\"\"Checks if a single line looks like a valid user query.\"\"\"\n",
    "    q_text = q_text.strip()\n",
    "    if not q_text: return False\n",
    "    # More robust filtering based on common LLM reasoning/meta-commentary patterns\n",
    "    if q_text.startswith((\"- \", \"* \", \"Okay,\", \"First,\", \"Next,\", \"Now,\", \"Let me\", \"Wait,\", \"Also,\", \"###\", \"//\", \"```\", \"Queries\", \"That's\", \"This should\", \"Avoid\", \"Check for\", \"Example\", \"User Query:\", \"Generated Query:\")): return False\n",
    "    if q_text.endswith(\":\") or \"→\" in q_text: return False\n",
    "    if re.match(r\"^\\d+\\.\", q_text): return False\n",
    "    if len(q_text.split()) <= 1 and not re.search(r'[a-zA-Z]', q_text): return False\n",
    "    if \"/\" in q_text and \".\" in q_text and \" \" not in q_text: return False\n",
    "    # Filter lines that are likely descriptions of tools or parameters\n",
    "    if any(tool_name in q_text.lower() for tool_name in [\"get_weather\", \"get_news\", \"get_current_location\"]):\n",
    "        if \"parameter\" in q_text.lower() or \"require\" in q_text.lower() or \"tool\" in q_text.lower():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def remove_think_blocks(text: str) -> str:\n",
    "    \"\"\"Removes <think>...</think> blocks from the text.\"\"\"\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL | re.IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92ea68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 1: Generate Diverse User Queries ('q') ---\n",
    "\n",
    "def generate_candidate_qs_with_llm(\n",
    "    tool_schemas_str: str,\n",
    "    num_to_generate: int,\n",
    "    existing_qs_list: List[str],\n",
    ") -> List[str]:\n",
    "    \"\"\"Generates candidate 'q' strings using the LLM, removing think blocks.\"\"\"\n",
    "    \n",
    "    system_prompt = f\"\"\"Your ONLY task is to generate realistic, diverse user queries or requests ('q') suitable for an AI assistant with access to specific tools. These queries should be answerable using the provided tools. Vary the complexity, phrasing (questions, commands), and the tools potentially required.\n",
    "\n",
    "**CRITICAL INSTRUCTIONS:**\n",
    "1.  Output ONLY the raw user queries.\n",
    "2.  Each query MUST be on a new line.\n",
    "3.  **ABSOLUTELY DO NOT** include:\n",
    "    * Explanations, comments, or justifications.\n",
    "    * Thinking processes, reasoning steps (including anything like `<think>...</think>`).\n",
    "    * Numbered lists, bullet points, or any formatting other than one query per line.\n",
    "    * Any text before the first query or after the last query.\n",
    "\"\"\"\n",
    "\n",
    "    examples_prompt = \"\"\n",
    "    if existing_qs_list:\n",
    "        sample_existing = random.sample(existing_qs_list, min(len(existing_qs_list), 5))\n",
    "        examples_prompt = \"Critically, avoid generating queries too similar to these examples:\\n- \" + \"\\n- \".join(sample_existing) + \"\\n\\n\"\n",
    "\n",
    "    user_prompt = f\"\"\"Based on the following available tools: {tool_schemas_str}\n",
    "Generate exactly {num_to_generate} diverse user queries ('q'). Remember to vary the required tools, complexity, and phrasing. {examples_prompt}Output ONLY the queries, one per line:\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    try:\n",
    "        print(f\"--- Calling LLM ({LLM_MODEL_NAME}) to generate ~{num_to_generate} queries ---\")\n",
    "        completion = client.chat.completions.create(\n",
    "            model=LLM_MODEL_NAME, messages=messages, temperature=0.8, max_tokens=4096,\n",
    "        )\n",
    "        raw_llm_output = completion.choices[0].message.content\n",
    "        print(\"--- LLM Response Received ---\")\n",
    "    except APIError as e:\n",
    "        print(f\"LLM API Error: {e}\"); return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during LLM call: {e}\"); return []\n",
    "    cleaned_output = remove_think_blocks(raw_llm_output)\n",
    "    candidate_qs = []\n",
    "    raw_lines = cleaned_output.split('\\n')\n",
    "    print(f\"--- Lines after removing <think> blocks: {len(raw_lines)} ---\") # Debugging\n",
    "    for line in raw_lines:\n",
    "        clean_line = line.strip()\n",
    "        if is_valid_query_line(clean_line):\n",
    "            candidate_qs.append(clean_line)\n",
    "        elif clean_line:\n",
    "             print(f\"Filtered out invalid line: '{clean_line}'\")\n",
    "\n",
    "    print(f\"--- Parsed {len(candidate_qs)} potentially valid candidate queries ---\")\n",
    "    return candidate_qs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8100ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Calling LLM (deepseek-r1) to generate ~5 queries ---\n",
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 7 ---\n",
      "--- Parsed 5 potentially valid candidate queries ---\n",
      "['Set up a meeting with the marketing team on March 12th from 2 PM to 3:30 PM.', 'Show me all events between March 10 and March 15.', \"Add a calendar entry for tomorrow's dentist appointment at 9 AM lasting one hour.\", 'Search the web for recent breakthroughs in renewable energy storage.', \"Check if I'm free between 10 AM and noon on March 20th.\"]\n"
     ]
    }
   ],
   "source": [
    "candidate_qs_strings = generate_candidate_qs_with_llm(\n",
    "    tool_schemas_json,\n",
    "    num_to_generate=5,\n",
    "    existing_qs_list=[],\n",
    ")\n",
    "\n",
    "print(candidate_qs_strings) # Debugging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e32ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/minpeter/.anaconda3/envs/py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Korean Sentence Transformer model...\n",
      "Model loaded.\n",
      "Encoding sentences...\n",
      "Encoding complete.\n",
      "\n",
      "--- Sentence Embedding Cosine Similarity ---\n",
      "Candidate vs Reference 1: 0.7844\n",
      "Candidate vs Reference 2: 0.7780\n",
      "\n",
      "Maximum Similarity Score: 0.7844\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 설치: pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch # sentence-transformers가 내부적으로 사용\n",
    "\n",
    "# 한국어 사전 훈련 모델 로드 (다양한 모델 사용 가능)\n",
    "# 예시: 'jhgan/ko-sbert-sts', 'snunlp/KR-SBERT-V40K-klueNLI-augSTS' 등\n",
    "# 모델 목록: https://huggingface.co/models?language=ko&library=sentence-transformers\n",
    "print(\"Loading Korean Sentence Transformer model...\")\n",
    "# model = SentenceTransformer('jhgan/ko-sbert-sts')\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# 비교할 텍스트\n",
    "references_ko = [\n",
    "    \"The cat was found under the bed\",\n",
    "    \"The cat was under the bed\"\n",
    "]\n",
    "candidate_ko = \"The cat likes to eat Churu\"\n",
    "\n",
    "# 문장 임베딩 계산\n",
    "# 참고: GPU 사용 가능 시 자동으로 활용하여 속도 향상\n",
    "print(\"Encoding sentences...\")\n",
    "ref_embeddings = model.encode(references_ko, convert_to_tensor=True)\n",
    "cand_embedding = model.encode(candidate_ko, convert_to_tensor=True)\n",
    "print(\"Encoding complete.\")\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "# 후보 문장과 각 참조 문장 간의 유사도 계산\n",
    "cosine_scores = util.pytorch_cos_sim(cand_embedding, ref_embeddings)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n--- Sentence Embedding Cosine Similarity ---\")\n",
    "for i, score in enumerate(cosine_scores[0]): # cand_embedding은 하나이므로 [0] 인덱스 사용\n",
    "    print(f\"Candidate vs Reference {i+1}: {score.item():.4f}\")\n",
    "\n",
    "# 여러 참조 문장 중 가장 높은 유사도 선택\n",
    "max_similarity = torch.max(cosine_scores[0]).item()\n",
    "print(f\"\\nMaximum Similarity Score: {max_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d21d84c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Korean Sentence Transformer model...\n",
      "Model 'snunlp/KR-SBERT-V40K-klueNLI-augSTS' loaded successfully.\n",
      "Model moved to GPU.\n",
      "Encoding 3 existing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing queries encoded.\n",
      "Encoding 5 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 131.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 5 candidates for diversity against 3 existing/accepted queries ---\n",
      "Accepting (MaxSim 0.655 <= 0.8): \"오늘 서울 날씨 알려줄래?\"\n",
      "Accepting (MaxSim 0.527 <= 0.8): \"제주도 가볼만한 곳\"\n",
      "Accepting (MaxSim 0.757 <= 0.8): \"파이썬 웹 개발 방법\"\n",
      "Accepting (MaxSim 0.476 <= 0.8): \"점심 메뉴 추천\"\n",
      "\n",
      "--- Accepted 4 new diverse query objects this round ---\n",
      "\n",
      "--- Accepted Queries ---\n",
      "1. Query: \"오늘 서울 날씨 알려줄래?\"\n",
      "   Max Similarity: 0.6547\n",
      "   Avg Similarity: 0.4588\n",
      "   Most Similar (3): {'오늘 날씨 어때?': 0.6547, '서울 맛집 추천해줘': 0.5066, '파이썬으로 웹사이트 만드는 법 알려줘': 0.2152}\n",
      "--------------------\n",
      "2. Query: \"제주도 가볼만한 곳\"\n",
      "   Max Similarity: 0.5267\n",
      "   Avg Similarity: 0.2935\n",
      "   Most Similar (3): {'서울 맛집 추천해줘': 0.5267, '오늘 날씨 어때?': 0.2773, '오늘 서울 날씨 알려줄래?': 0.2509}\n",
      "--------------------\n",
      "3. Query: \"파이썬 웹 개발 방법\"\n",
      "   Max Similarity: 0.7572\n",
      "   Avg Similarity: 0.2394\n",
      "   Most Similar (3): {'파이썬으로 웹사이트 만드는 법 알려줘': 0.7572, '서울 맛집 추천해줘': 0.1332, '제주도 가볼만한 곳': 0.125}\n",
      "--------------------\n",
      "4. Query: \"점심 메뉴 추천\"\n",
      "   Max Similarity: 0.4759\n",
      "   Avg Similarity: 0.2689\n",
      "   Most Similar (3): {'서울 맛집 추천해줘': 0.4759, '제주도 가볼만한 곳': 0.3711, '오늘 날씨 어때?': 0.2893}\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import heapq # top_n_similar 계산을 위해 유지\n",
    "\n",
    "# --- 모델 로딩 (애플리케이션 시작 시 한 번 수행하는 것이 이상적) ---\n",
    "# 한국어 사전 훈련 모델 로드\n",
    "# 사용 가능한 모델 예시: 'jhgan/ko-sbert-sts', 'snunlp/KR-SBERT-V40K-klueNLI-augSTS' 등\n",
    "print(\"Loading Korean Sentence Transformer model...\")\n",
    "# model_name = 'jhgan/ko-sbert-sts'\n",
    "model_name = 'snunlp/KR-SBERT-V40K-klueNLI-augSTS'\n",
    "try:\n",
    "    # GPU 사용 가능 시 자동으로 활용\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print(f\"Model '{model_name}' loaded successfully.\")\n",
    "    # 모델을 GPU로 이동 (사용 가능한 경우)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(torch.device(\"cuda\"))\n",
    "        print(\"Model moved to GPU.\")\n",
    "    else:\n",
    "        print(\"GPU not available, using CPU.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Sentence Transformer model: {e}\")\n",
    "    model = None # 모델 로딩 실패 시 None으로 설정\n",
    "\n",
    "# --- 개선된 필터링 함수 ---\n",
    "def filter_and_score_qs_sentence_transformer(\n",
    "    candidate_qs: List[str],\n",
    "    existing_query_objects: List[Dict[str, Any]],\n",
    "    model: SentenceTransformer, # 로드된 모델을 인자로 받음\n",
    "    similarity_threshold: float = 0.8,\n",
    "    top_n_similar: int = 10\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Filters candidate questions based on maximum semantic similarity using Sentence Transformers\n",
    "    and scores the accepted ones.\n",
    "\n",
    "    Args:\n",
    "        candidate_qs: List of new candidate question strings.\n",
    "        existing_query_objects: List of dictionaries, each representing an existing query\n",
    "                                (must contain at least a 'q' key with the query string).\n",
    "        model: The pre-loaded Sentence Transformer model.\n",
    "        similarity_threshold: The maximum similarity score allowed for a candidate to be accepted.\n",
    "        top_n_similar: The number of most similar existing questions to record for accepted candidates.\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries, each representing an accepted new query with similarity scores.\n",
    "    \"\"\"\n",
    "    if not model:\n",
    "        print(\"Error: Sentence Transformer model is not loaded. Cannot perform filtering.\")\n",
    "        return []\n",
    "\n",
    "    if not candidate_qs:\n",
    "        print(\"No candidate questions provided.\")\n",
    "        return []\n",
    "\n",
    "    newly_accepted_query_objects = []\n",
    "    existing_qs_list = [obj['q'] for obj in existing_query_objects]\n",
    "\n",
    "    # --- 임베딩 계산 ---\n",
    "    # 기존 질문 임베딩 (비어있지 않은 경우에만 계산)\n",
    "    existing_embeddings = None\n",
    "    if existing_qs_list:\n",
    "        print(f\"Encoding {len(existing_qs_list)} existing queries...\")\n",
    "        # 배치 처리 및 GPU 활용 (모델이 GPU에 있다면)\n",
    "        existing_embeddings = model.encode(existing_qs_list, convert_to_tensor=True, show_progress_bar=True)\n",
    "        print(\"Existing queries encoded.\")\n",
    "\n",
    "    # 후보 질문 임베딩\n",
    "    print(f\"Encoding {len(candidate_qs)} candidate queries...\")\n",
    "    candidate_embeddings = model.encode(candidate_qs, convert_to_tensor=True, show_progress_bar=True)\n",
    "    print(\"Candidate queries encoded.\")\n",
    "\n",
    "    # 비교 대상 질문 목록 및 임베딩 (반복문 내에서 업데이트됨)\n",
    "    # 초기에는 기존 질문들로 설정\n",
    "    all_qs_strings_for_comparison = list(existing_qs_list)\n",
    "    # .clone()을 사용하여 원본 existing_embeddings가 변경되지 않도록 함\n",
    "    all_embeddings_for_comparison = existing_embeddings.clone() if existing_embeddings is not None else None\n",
    "\n",
    "    print(f\"\\n--- Filtering {len(candidate_qs)} candidates for diversity against {len(all_qs_strings_for_comparison)} existing/accepted queries ---\")\n",
    "\n",
    "    # 후보 질문들을 순회하며 필터링\n",
    "    for i, q_new in enumerate(candidate_qs):\n",
    "        q_new_lower = q_new.lower()\n",
    "        cand_embedding = candidate_embeddings[i] # 해당 후보의 미리 계산된 임베딩 사용\n",
    "\n",
    "        # 1. 정확히 동일한 질문인지 확인 (소문자 기준)\n",
    "        is_exact_duplicate = any(q_new_lower == q_old.lower() for q_old in all_qs_strings_for_comparison)\n",
    "        if is_exact_duplicate:\n",
    "            # print(f\"Skipping exact duplicate: \\\"{q_new}\\\"\") # 로그 출력 필요 시 주석 해제\n",
    "            continue\n",
    "\n",
    "        # 2. 기존/수락된 질문들과의 유사도 계산\n",
    "        max_similarity = 0.0\n",
    "        avg_similarity = 0.0\n",
    "        similarities_list = [] # (score, query) 튜플 저장 리스트\n",
    "\n",
    "        # 비교 대상 임베딩이 있는 경우에만 유사도 계산\n",
    "        if all_embeddings_for_comparison is not None and all_embeddings_for_comparison.shape[0] > 0:\n",
    "            # 코사인 유사도 계산 (후보 1개 vs 모든 비교 대상)\n",
    "            # cand_embedding 차원을 [1, embedding_dim]으로 맞춰줌\n",
    "            cosine_scores = util.pytorch_cos_sim(cand_embedding.unsqueeze(0), all_embeddings_for_comparison)[0] # 결과는 tensor([score1, score2, ...])\n",
    "\n",
    "            # CPU로 이동 후 numpy 배열로 변환하여 사용 (GPU 메모리 절약 및 호환성)\n",
    "            cosine_scores_cpu = cosine_scores.cpu().numpy()\n",
    "\n",
    "            if cosine_scores_cpu.size > 0: # 유사도 점수가 계산된 경우\n",
    "                max_similarity = np.max(cosine_scores_cpu)\n",
    "                avg_similarity = np.mean(cosine_scores_cpu)\n",
    "                # 유사도 점수와 해당 질문 텍스트를 묶어서 리스트 생성\n",
    "                similarities_list = list(zip(cosine_scores_cpu, all_qs_strings_for_comparison))\n",
    "            else: # 비교 대상은 있으나 어떤 이유로든 점수 계산이 안된 경우 (이론상 발생하기 어려움)\n",
    "                max_similarity = 0.0\n",
    "                avg_similarity = 0.0\n",
    "                similarities_list = []\n",
    "\n",
    "        # 3. Alpaca 스타일 필터링: 최대 유사도가 임계값보다 높으면 건너뛰기\n",
    "        if max_similarity > similarity_threshold:\n",
    "            print(f\"Skipping (MaxSim {max_similarity:.3f} > {similarity_threshold}): \\\"{q_new}\\\"\")\n",
    "            continue\n",
    "\n",
    "        # 4. 필터를 통과한 경우: 결과 저장 및 다음 비교를 위해 추가\n",
    "        print(f\"Accepting (MaxSim {max_similarity:.3f} <= {similarity_threshold}): \\\"{q_new}\\\"\")\n",
    "\n",
    "        # 가장 유사한 N개 찾기 (heapq 사용)\n",
    "        most_similar_dict = {}\n",
    "        if similarities_list:\n",
    "            # 실제 top_n 개수는 유사도 리스트 크기와 top_n_similar 중 작은 값\n",
    "            actual_top_n = min(top_n_similar, len(similarities_list))\n",
    "            # 점수가 높은 순서대로 정렬 (튜플의 첫 번째 요소인 점수 기준)\n",
    "            top_n = heapq.nlargest(actual_top_n, similarities_list, key=lambda item: item[0])\n",
    "            # 딕셔너리로 변환 (소수점 4자리까지 반올림, 0.01 이하 점수는 제외)\n",
    "            most_similar_dict = {q: round(float(score), 4) for score, q in top_n if float(score) > 0.01}\n",
    "\n",
    "\n",
    "        # 새로운 질문 객체 생성\n",
    "        new_obj = {\n",
    "            \"q\": q_new,\n",
    "            \"max_similarity_score_against_all\": round(float(max_similarity), 4), # float로 변환\n",
    "            \"avg_similarity_score\": round(float(avg_similarity), 4), # float로 변환\n",
    "            \"most_similar_instructions\": most_similar_dict # 기존 키 이름 유지\n",
    "        }\n",
    "        newly_accepted_query_objects.append(new_obj)\n",
    "\n",
    "        # 다음 후보 비교를 위해 현재 수락된 질문과 임베딩을 비교 대상 목록에 추가\n",
    "        all_qs_strings_for_comparison.append(q_new)\n",
    "        # 임베딩 추가: all_embeddings_for_comparison이 None이면 새로 생성, 아니면 이어붙임\n",
    "        cand_embedding_expanded = cand_embedding.unsqueeze(0) # 차원 맞추기 [1, embedding_dim]\n",
    "        if all_embeddings_for_comparison is None:\n",
    "            all_embeddings_for_comparison = cand_embedding_expanded\n",
    "        else:\n",
    "            all_embeddings_for_comparison = torch.cat((all_embeddings_for_comparison, cand_embedding_expanded), dim=0)\n",
    "\n",
    "    print(f\"\\n--- Accepted {len(newly_accepted_query_objects)} new diverse query objects this round ---\")\n",
    "    return newly_accepted_query_objects\n",
    "\n",
    "# --- 예시 사용법 ---\n",
    "if __name__ == \"__main__\":\n",
    "    if model: # 모델이 성공적으로 로드되었을 때만 실행\n",
    "        # 기존에 존재하는 질문들 (예시)\n",
    "        existing_queries = [\n",
    "            {\"q\": \"오늘 날씨 어때?\", \"other_data\": 1},\n",
    "            {\"q\": \"서울 맛집 추천해줘\", \"other_data\": 2},\n",
    "            {\"q\": \"파이썬으로 웹사이트 만드는 법 알려줘\", \"other_data\": 3}\n",
    "        ]\n",
    "\n",
    "        # 새로 들어온 후보 질문들 (예시)\n",
    "        candidate_queries = [\n",
    "            \"오늘 서울 날씨 알려줄래?\", # 기존 질문과 유사\n",
    "            \"제주도 가볼만한 곳\",\n",
    "            \"파이썬 웹 개발 방법\", # 기존 질문과 유사\n",
    "            \"점심 메뉴 추천\",\n",
    "            \"오늘 날씨 어때?\" # 기존 질문과 정확히 일치\n",
    "        ]\n",
    "\n",
    "        # 필터링 및 스코어링 실행\n",
    "        accepted_queries = filter_and_score_qs_sentence_transformer(\n",
    "            candidate_qs=candidate_queries,\n",
    "            existing_query_objects=existing_queries,\n",
    "            model=model,\n",
    "            similarity_threshold=0.8, # 유사도 임계값 (조정 가능)\n",
    "            top_n_similar=3\n",
    "        )\n",
    "\n",
    "        print(\"\\n--- Accepted Queries ---\")\n",
    "        for i, query_obj in enumerate(accepted_queries):\n",
    "            print(f\"{i+1}. Query: \\\"{query_obj['q']}\\\"\")\n",
    "            print(f\"   Max Similarity: {query_obj['max_similarity_score_against_all']:.4f}\")\n",
    "            print(f\"   Avg Similarity: {query_obj['avg_similarity_score']:.4f}\")\n",
    "            print(f\"   Most Similar ({len(query_obj['most_similar_instructions'])}): {query_obj['most_similar_instructions']}\")\n",
    "            print(\"-\" * 20)\n",
    "    else:\n",
    "        print(\"Skipping example usage because the model could not be loaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d91003c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing query file found (diverse_queries_with_scores_v4.json). Starting fresh.\n",
      "Starting Generation Process.\n",
      "Initial query objects loaded: 0\n",
      "Targeting 10 new queries per turn for 3 turns.\n",
      "Overall target: 30 query objects.\n",
      "Using Similarity Threshold (Sentence Transformer): 0.8\n",
      "------------------------------\n",
      "\n",
      "=== Turn 1/3 ===\n",
      "\n",
      "--- Turn 1 | Attempt 1/5 ---\n",
      "Current total query objects: 0\n",
      "Goal for this turn: 0/10 new queries\n",
      "--- Calling LLM (deepseek-r1) to generate ~15 queries ---\n",
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 17 ---\n",
      "--- Parsed 15 potentially valid candidate queries ---\n",
      "Encoding 15 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 15 candidates for diversity against 0 existing/accepted queries ---\n",
      "Accepting (MaxSim 0.000 <= 0.8): \"Add a meeting titled \"Project Kickoff\" for September 12th from 2:30 PM to 4:00 PM\"\n",
      "Accepting (MaxSim 0.667 <= 0.8): \"Show my calendar events between October 1st and October 7th\"\n",
      "Accepting (MaxSim 0.788 <= 0.8): \"Find recent news about quantum computing breakthroughs\"\n",
      "Accepting (MaxSim 0.729 <= 0.8): \"Can you schedule a doctor's appointment on 2024-03-05 at 9:15 AM for 45 minutes?\"\n",
      "Skipping (MaxSim 0.807 > 0.8): \"Check if I have any conflicts on November 18th between 1 PM and 3 PM\"\n",
      "Accepting (MaxSim 0.794 <= 0.8): \"Search for top-rated Italian restaurants in Chicago and add a dinner reservation to my calendar\"\n",
      "Skipping (MaxSim 0.809 > 0.8): \"How do I grant this app permission to manage my calendar?\"\n",
      "Accepting (MaxSim 0.764 <= 0.8): \"Create an all-day event called \"Anniversary\" on 2024-05-21\"\n",
      "Accepting (MaxSim 0.792 <= 0.8): \"What’s my availability like next Wednesday morning?\"\n",
      "Skipping (MaxSim 0.829 > 0.8): \"Look up when the next solar eclipse occurs and block that time\"\n",
      "Accepting (MaxSim 0.748 <= 0.8): \"Display all events from December 20th to December 31st\"\n",
      "Skipping (MaxSim 0.809 > 0.8): \"Set up a recurring team sync every Friday at 10 AM starting this week\"\n",
      "Skipping (MaxSim 0.810 > 0.8): \"Find flight options from JFK to LAX on April 23rd and add the chosen itinerary to my schedule\"\n",
      "Skipping (MaxSim 0.846 > 0.8): \"Can you check my calendar for open slots tomorrow afternoon?\"\n",
      "Skipping (MaxSim 0.821 > 0.8): \"Authorize calendar integration so I can view my upcoming conferences\"\n",
      "\n",
      "--- Accepted 8 new diverse query objects this round ---\n",
      "Accepted 8 new diverse query objects in this attempt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Turn 1 | Attempt 2/5 ---\n",
      "Current total query objects: 8\n",
      "Goal for this turn: 8/10 new queries\n",
      "--- Calling LLM (deepseek-r1) to generate ~7 queries ---\n",
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 9 ---\n",
      "--- Parsed 7 potentially valid candidate queries ---\n",
      "Encoding 8 existing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 115.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing queries encoded.\n",
      "Encoding 7 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 128.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 7 candidates for diversity against 8 existing/accepted queries ---\n",
      "Accepting (MaxSim 0.796 <= 0.8): \"Schedule a dentist appointment for next Thursday from 10:00 AM to 11:30 AM with the summary \"Root Canal Checkup\"\"\n",
      "Skipping (MaxSim 0.851 > 0.8): \"Can you show me all calendar entries between June 1st and June 15th?\"\n",
      "Skipping (MaxSim 0.820 > 0.8): \"How do I authorize calendar access for the assistant to manage my events?\"\n",
      "Skipping (MaxSim 0.810 > 0.8): \"Look up the current weather forecast in Tokyo this weekend\"\n",
      "Skipping (MaxSim 0.822 > 0.8): \"Create a 2-hour block titled \"Focus Time\" starting today at 3:00 PM\"\n",
      "Skipping (MaxSim 0.831 > 0.8): \"What are the latest trends in artificial intelligence research according to recent articles?\"\n",
      "Skipping (MaxSim 0.812 > 0.8): \"Check if I have any meetings scheduled this Friday afternoon\"\n",
      "\n",
      "--- Accepted 1 new diverse query objects this round ---\n",
      "Accepted 1 new diverse query objects in this attempt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Turn 1 | Attempt 3/5 ---\n",
      "Current total query objects: 9\n",
      "Goal for this turn: 9/10 new queries\n",
      "--- Calling LLM (deepseek-r1) to generate ~6 queries ---\n",
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 8 ---\n",
      "--- Parsed 6 potentially valid candidate queries ---\n",
      "Encoding 9 existing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 109.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing queries encoded.\n",
      "Encoding 6 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 128.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 6 candidates for diversity against 9 existing/accepted queries ---\n",
      "Skipping (MaxSim 0.850 > 0.8): \"Authorize calendar access and show my events from June 5th to June 10th\"\n",
      "Skipping (MaxSim 0.801 > 0.8): \"Search for TED Talk schedules in September 2024 and create reminder events for three I might like\"\n",
      "Skipping (MaxSim 0.830 > 0.8): \"Block off August 12th 2024 from 8:00 AM to 12:00 PM for \"Strategic Planning Workshop\"\"\n",
      "Skipping (MaxSim 0.826 > 0.8): \"Check if I have conflicts on July 4th and find local fireworks display times\"\n",
      "Skipping (MaxSim 0.810 > 0.8): \"Enable calendar permissions then schedule a client call on 2024-11-14 from 14:30 to 15:15\"\n",
      "Accepting (MaxSim 0.784 <= 0.8): \"What's the date range for CES 2025? Create placeholder events spanning those dates with \"Tech Conference\" summaries\"\n",
      "\n",
      "--- Accepted 1 new diverse query objects this round ---\n",
      "Accepted 1 new diverse query objects in this attempt.\n",
      "--- Turn 1 goal reached (10 new queries added). ---\n",
      "Saved 10 query objects to diverse_queries_with_scores_v4.json\n",
      "--- End of Turn 1. Total query objects now: 10. Added this turn: 10. ---\n",
      "\n",
      "=== Turn 2/3 ===\n",
      "\n",
      "--- Turn 2 | Attempt 1/5 ---\n",
      "Current total query objects: 10\n",
      "Goal for this turn: 0/10 new queries\n",
      "--- Calling LLM (deepseek-r1) to generate ~15 queries ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 17 ---\n",
      "--- Parsed 15 potentially valid candidate queries ---\n",
      "Encoding 10 existing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 114.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing queries encoded.\n",
      "Encoding 15 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 15 candidates for diversity against 10 existing/accepted queries ---\n",
      "Skipping (MaxSim 0.816 > 0.8): \"Schedule a project review for 2024-04-10 from 2:00 PM to 3:30 PM\"\n",
      "Skipping (MaxSim 0.811 > 0.8): \"List all my calendar entries between April 5th and April 12th, 2024\"\n",
      "Accepting (MaxSim 0.748 <= 0.8): \"Search the web for the latest AI conference dates in 2024\"\n",
      "Skipping (MaxSim 0.876 > 0.8): \"Book a dentist appointment on March 15th at 10:00 AM lasting one hour\"\n",
      "Accepting (MaxSim 0.770 <= 0.8): \"Authorize access to manage my calendar events\"\n",
      "Skipping (MaxSim 0.839 > 0.8): \"What's the weather forecast for New York City this weekend?\"\n",
      "Accepting (MaxSim 0.761 <= 0.8): \"Create a marketing team meeting on June 5th, 2024 from 1:30 PM to 2:30 PM\"\n",
      "Skipping (MaxSim 0.806 > 0.8): \"Do I have any events scheduled on July 4th, 2024?\"\n",
      "Skipping (MaxSim 0.810 > 0.8): \"Look up the capital of Brazil and add a study session tomorrow at 4:00 PM\"\n",
      "Skipping (MaxSim 0.803 > 0.8): \"Check my availability on August 20th between 3:00 PM and 5:00 PM\"\n",
      "Skipping (MaxSim 0.887 > 0.8): \"Find top-rated Italian restaurants nearby and remind me about dinner reservations this Friday at 7:00 PM\"\n",
      "Accepting (MaxSim 0.793 <= 0.8): \"Show all meetings scheduled during the first week of September 2024\"\n",
      "Skipping (MaxSim 0.854 > 0.8): \"Search for 'time management techniques' and block time to read about them next Wednesday afternoon\"\n",
      "Skipping (MaxSim 0.847 > 0.8): \"Add a reminder for Sarah's birthday on May 12th at 9:00 AM\"\n",
      "Skipping (MaxSim 0.862 > 0.8): \"What are the dates for the 2024 Olympics opening ceremony? Schedule a viewing event\"\n",
      "\n",
      "--- Accepted 4 new diverse query objects this round ---\n",
      "Accepted 4 new diverse query objects in this attempt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Turn 2 | Attempt 2/5 ---\n",
      "Current total query objects: 14\n",
      "Goal for this turn: 4/10 new queries\n",
      "--- Calling LLM (deepseek-r1) to generate ~11 queries ---\n",
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 13 ---\n",
      "--- Parsed 11 potentially valid candidate queries ---\n",
      "Encoding 14 existing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing queries encoded.\n",
      "Encoding 11 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 11 candidates for diversity against 14 existing/accepted queries ---\n",
      "Accepting (MaxSim 0.783 <= 0.8): \"Check my schedule for any conflicts on November 22nd between 3 PM and 5 PM.\"\n",
      "Skipping (MaxSim 0.825 > 0.8): \"How do I grant permission for you to manage my calendar appointments?\"\n",
      "Skipping (MaxSim 0.864 > 0.8): \"Find upcoming tech conferences in Berlin and add the DevOps Days event to my agenda.\"\n",
      "Skipping (MaxSim 0.879 > 0.8): \"Set up a recurring weekly team sync every Monday at 10 AM starting October 7th.\"\n",
      "Skipping (MaxSim 0.898 > 0.8): \"What’s on my calendar from tomorrow morning through Friday evening?\"\n",
      "Accepting (MaxSim 0.773 <= 0.8): \"Search for volunteer opportunities in Austin and block time for Habitat for Humanity on September 21st.\"\n",
      "Accepting (MaxSim 0.780 <= 0.8): \"Can you see if I’m free on December 3rd at 2 PM for a client workshop?\"\n",
      "Skipping (MaxSim 0.855 > 0.8): \"Look up citywide recycling dates and schedule reminders the day before each pickup.\"\n",
      "Skipping (MaxSim 0.832 > 0.8): \"I need to allow calendar access before you can check my availability next week.\"\n",
      "Accepting (MaxSim 0.797 <= 0.8): \"Add a webinar about AI ethics to my schedule on 2024-11-14 from 1:30 PM to 3 PM.\"\n",
      "Skipping (MaxSim 0.806 > 0.8): \"Show me all booked slots between January 10th and January 25th, 2025.\"\n",
      "\n",
      "--- Accepted 4 new diverse query objects this round ---\n",
      "Accepted 4 new diverse query objects in this attempt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Turn 2 | Attempt 3/5 ---\n",
      "Current total query objects: 18\n",
      "Goal for this turn: 8/10 new queries\n",
      "--- Calling LLM (deepseek-r1) to generate ~7 queries ---\n",
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 9 ---\n",
      "--- Parsed 7 potentially valid candidate queries ---\n",
      "Encoding 18 existing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing queries encoded.\n",
      "Encoding 7 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 7 candidates for diversity against 18 existing/accepted queries ---\n",
      "Skipping (MaxSim 0.811 > 0.8): \"Check my schedule from June 10th to June 15th and create a 'Vacation' event if available\"\n",
      "Accepting (MaxSim 0.796 <= 0.8): \"Find the dates for Coachella 2024 and block my calendar with 'Music Festival'\"\n",
      "Skipping (MaxSim 0.853 > 0.8): \"Set up a reminder for my mom's birthday on August 8th from 9 AM to 10 AM\"\n",
      "Accepting (MaxSim 0.734 <= 0.8): \"What do I have scheduled on February 14th next year?\"\n",
      "Skipping (MaxSim 0.801 > 0.8): \"Search for TED Talk events in Boston this fall and schedule attendance on the first available date\"\n",
      "Skipping (MaxSim 0.852 > 0.8): \"Authorize calendar access and add a 'Financial Review' meeting next Friday at 3 PM\"\n",
      "Skipping (MaxSim 0.830 > 0.8): \"Look up when the next solar eclipse occurs and mark it as 'Sky Event' in my calendar\"\n",
      "\n",
      "--- Accepted 2 new diverse query objects this round ---\n",
      "Accepted 2 new diverse query objects in this attempt.\n",
      "--- Turn 2 goal reached (10 new queries added). ---\n",
      "Saved 20 query objects to diverse_queries_with_scores_v4.json\n",
      "--- End of Turn 2. Total query objects now: 20. Added this turn: 10. ---\n",
      "\n",
      "=== Turn 3/3 ===\n",
      "\n",
      "--- Turn 3 | Attempt 1/5 ---\n",
      "Current total query objects: 20\n",
      "Goal for this turn: 0/10 new queries\n",
      "--- Calling LLM (deepseek-r1) to generate ~15 queries ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 17 ---\n",
      "--- Parsed 15 potentially valid candidate queries ---\n",
      "Encoding 20 existing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing queries encoded.\n",
      "Encoding 15 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 15 candidates for diversity against 20 existing/accepted queries ---\n",
      "Accepting (MaxSim 0.799 <= 0.8): \"Check if I have any meetings scheduled between March 10th and March 15th.\"\n",
      "Skipping (MaxSim 0.965 > 0.8): \"Find the dates for Coachella 2024 and add them to my calendar as \"Music Festival\".\"\n",
      "Skipping (MaxSim 0.853 > 0.8): \"Block off next Thursday from 3 PM to 5 PM for a project deadline review.\"\n",
      "Skipping (MaxSim 0.800 > 0.8): \"What public holidays in Japan occur in Q3 2024? Create calendar entries for each.\"\n",
      "Skipping (MaxSim 0.802 > 0.8): \"Search for TED Talk livestream schedules this month and set reminders 10 minutes prior.\"\n",
      "Skipping (MaxSim 0.870 > 0.8): \"Schedule a webinar titled \"AI Ethics Panel\" on 2024-09-12 from 2:30 PM to 4:00 PM.\"\n",
      "Skipping (MaxSim 0.809 > 0.8): \"Show all events tagged as \"Client Meeting\" from April 1st to April 30th.\"\n",
      "Skipping (MaxSim 0.843 > 0.8): \"How long does standard shipping take from Germany? Add a reminder 5 days before my package's expected arrival.\"\n",
      "Skipping (MaxSim 0.812 > 0.8): \"When does the Louvre Museum open on Sundays? Block morning hours on July 7th for a visit.\"\n",
      "Skipping (MaxSim 0.809 > 0.8): \"Create a calendar event for my sister's graduation ceremony on June 8th from 10 AM to 12 PM.\"\n",
      "Skipping (MaxSim 0.843 > 0.8): \"List all conferences happening between August 1st and August 10th, then reserve those dates as \"Industry Events\".\"\n",
      "Skipping (MaxSim 0.861 > 0.8): \"Schedule recurring weekly team syncs every Monday at 9 AM starting May 6th (handled as single instance).\"\n",
      "Skipping (MaxSim 0.815 > 0.8): \"Find the release date for the new smartphone model and mark it as \"Product Launch Day\".\"\n",
      "Skipping (MaxSim 0.881 > 0.8): \"Check availability for a 2-hour coding workshop slot between March 20th and March 25th.\"\n",
      "Skipping (MaxSim 0.841 > 0.8): \"Search for local farmers' market dates in May and add Saturday events to my calendar.\"\n",
      "\n",
      "--- Accepted 1 new diverse query objects this round ---\n",
      "Accepted 1 new diverse query objects in this attempt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Turn 3 | Attempt 2/5 ---\n",
      "Current total query objects: 21\n",
      "Goal for this turn: 1/10 new queries\n",
      "--- Calling LLM (deepseek-r1) to generate ~14 queries ---\n",
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 16 ---\n",
      "--- Parsed 14 potentially valid candidate queries ---\n",
      "Encoding 21 existing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing queries encoded.\n",
      "Encoding 14 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 14 candidates for diversity against 21 existing/accepted queries ---\n",
      "Skipping (MaxSim 0.841 > 0.8): \"Add a reminder for my doctor's appointment on 2024-03-15 at 2:30 PM.\"\n",
      "Skipping (MaxSim 0.884 > 0.8): \"Check if I have meetings scheduled between April 1st and April 5th, 2024.\"\n",
      "Skipping (MaxSim 0.859 > 0.8): \"Search for upcoming tech conferences in Berlin and save the dates in my calendar.\"\n",
      "Skipping (MaxSim 0.859 > 0.8): \"Schedule a monthly team sync every third Thursday starting May 2024 at 11 AM.\"\n",
      "Skipping (MaxSim 0.867 > 0.8): \"Find recipe ideas for gluten-free desserts and block kitchen time Saturday afternoon.\"\n",
      "Skipping (MaxSim 0.924 > 0.8): \"Authorize calendar access to check my existing commitments.\"\n",
      "Skipping (MaxSim 0.812 > 0.8): \"What's my schedule looking like from September 9th to September 13th?\"\n",
      "Skipping (MaxSim 0.835 > 0.8): \"Set up a car maintenance reminder for June 10th at 8 AM with \"Oil Change\" as the title.\"\n",
      "Skipping (MaxSim 0.846 > 0.8): \"Look up city marathon dates worldwide and register available slots in October.\"\n",
      "Skipping (MaxSim 0.821 > 0.8): \"Can I attend a 3PM webinar on August 8th? Check for conflicts first.\"\n",
      "Skipping (MaxSim 0.803 > 0.8): \"Search for Lunar New Year dates in 2025 and mark them as cultural holidays.\"\n",
      "Skipping (MaxSim 0.873 > 0.8): \"Create an event called \"Project Retrospective\" from 2024-07-22 14:00 to 16:00.\"\n",
      "Skipping (MaxSim 0.829 > 0.8): \"Find parent-teacher conference templates and schedule ours for November 14th at 4PM.\"\n",
      "Skipping (MaxSim 0.827 > 0.8): \"Check availability for a weekend camping trip during the last week of May.\"\n",
      "\n",
      "--- Accepted 0 new diverse query objects this round ---\n",
      "Accepted 0 new diverse query objects in this attempt.\n",
      "Warning: No new diverse queries accepted in this attempt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Turn 3 | Attempt 3/5 ---\n",
      "Current total query objects: 21\n",
      "Goal for this turn: 1/10 new queries\n",
      "--- Calling LLM (deepseek-r1) to generate ~14 queries ---\n",
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 16 ---\n",
      "--- Parsed 14 potentially valid candidate queries ---\n",
      "Encoding 21 existing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing queries encoded.\n",
      "Encoding 14 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 14 candidates for diversity against 21 existing/accepted queries ---\n",
      "Skipping (MaxSim 0.821 > 0.8): \"Add a team brainstorming session on April 22nd from 10:30 AM to 12 PM.\"\n",
      "Skipping (MaxSim 0.845 > 0.8): \"Search for upcoming developer conferences in Berlin during October 2024.\"\n",
      "Accepting (MaxSim 0.771 <= 0.8): \"When does E3 2024 start? Block those three days with \"Gaming Expo\" titles.\"\n",
      "Skipping (MaxSim 0.818 > 0.8): \"Can you check if I'm free between August 12th and 16th for a potential vacation?\"\n",
      "Skipping (MaxSim 0.830 > 0.8): \"Schedule a car service appointment lasting 90 minutes on the next available weekday morning.\"\n",
      "Skipping (MaxSim 0.850 > 0.8): \"Find the dates for Paris Fashion Week 2024 and create tentative events labeled \"Fashion Show Prep\".\"\n",
      "Accepting (MaxSim 0.798 <= 0.8): \"What's my schedule look like on June 7th after 1 PM?\"\n",
      "Skipping (MaxSim 0.838 > 0.8): \"Create a recurring event for yoga every Wednesday at 7:30 AM beginning September 4th.\"\n",
      "Skipping (MaxSim 0.822 > 0.8): \"Look up the keynote times for Google I/O 2024 and reserve those slots as \"Tech Keynote\".\"\n",
      "Accepting (MaxSim 0.772 <= 0.8): \"Do I have any client calls scheduled between May 20th and May 24th?\"\n",
      "Skipping (MaxSim 0.819 > 0.8): \"Set a reminder to submit quarterly reports on 2024-03-25 from 3 PM to 3:10 PM.\"\n",
      "Skipping (MaxSim 0.831 > 0.8): \"Check availability for a 2-hour coding workshop between November 5th-9th.\"\n",
      "Skipping (MaxSim 0.854 > 0.8): \"Search for meteor shower peak dates in 2024 and add midnight viewing reminders.\"\n",
      "Skipping (MaxSim 0.816 > 0.8): \"Book a co-working space for March 18th from 8 AM to 5 PM with \"Deep Work Day\" as the title.\"\n",
      "\n",
      "--- Accepted 3 new diverse query objects this round ---\n",
      "Accepted 3 new diverse query objects in this attempt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Turn 3 | Attempt 4/5 ---\n",
      "Current total query objects: 24\n",
      "Goal for this turn: 4/10 new queries\n",
      "--- Calling LLM (deepseek-r1) to generate ~11 queries ---\n",
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 13 ---\n",
      "--- Parsed 11 potentially valid candidate queries ---\n",
      "Encoding 24 existing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing queries encoded.\n",
      "Encoding 11 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 11 candidates for diversity against 24 existing/accepted queries ---\n",
      "Skipping (MaxSim 0.815 > 0.8): \"Add a project deadline for 'Q4 Report' on 2024-11-25 from 3:00 PM to 4:00 PM\"\n",
      "Skipping (MaxSim 0.847 > 0.8): \"Show my calendar entries between August 10th and August 17th\"\n",
      "Skipping (MaxSim 0.805 > 0.8): \"Look up when Diwali starts this year and block those dates\"\n",
      "Skipping (MaxSim 0.821 > 0.8): \"Set up a parent-teacher conference call on May 6th at 4:30 PM for 20 minutes\"\n",
      "Skipping (MaxSim 0.812 > 0.8): \"Find current exhibitions at the Louvre Museum\"\n",
      "Skipping (MaxSim 0.868 > 0.8): \"Check if my calendar is free on October 12th at 2:00 PM\"\n",
      "Skipping (MaxSim 0.811 > 0.8): \"How do I enable calendar permissions for this assistant?\"\n",
      "Skipping (MaxSim 0.848 > 0.8): \"Search for local coding bootcamp schedules and add the July intake dates\"\n",
      "Accepting (MaxSim 0.772 <= 0.8): \"Create an all-day event titled 'Anniversary Vacation' on September 14th\"\n",
      "Skipping (MaxSim 0.842 > 0.8): \"What's the schedule for the Champions League final and can you mark it?\"\n",
      "Skipping (MaxSim 0.821 > 0.8): \"Verify if there's overlap between my 9 AM meeting and lunch plans on Friday\"\n",
      "\n",
      "--- Accepted 1 new diverse query objects this round ---\n",
      "Accepted 1 new diverse query objects in this attempt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Turn 3 | Attempt 5/5 ---\n",
      "Current total query objects: 25\n",
      "Goal for this turn: 5/10 new queries\n",
      "--- Calling LLM (deepseek-r1) to generate ~10 queries ---\n",
      "--- LLM Response Received ---\n",
      "--- Lines after removing <think> blocks: 12 ---\n",
      "--- Parsed 10 potentially valid candidate queries ---\n",
      "Encoding 25 existing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing queries encoded.\n",
      "Encoding 10 candidate queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate queries encoded.\n",
      "\n",
      "--- Filtering 10 candidates for diversity against 25 existing/accepted queries ---\n",
      "Skipping (MaxSim 0.864 > 0.8): \"Set up a team sync every Thursday at 4 PM starting April 4th for 30 minutes.\"\n",
      "Skipping (MaxSim 0.802 > 0.8): \"Search for upcoming developer conferences in Europe and block those dates.\"\n",
      "Skipping (MaxSim 0.842 > 0.8): \"Check if I'm available between May 7th morning and May 9th noon.\"\n",
      "Skipping (MaxSim 0.867 > 0.8): \"Authorize calendar permissions so you can view my upcoming appointments.\"\n",
      "Skipping (MaxSim 0.801 > 0.8): \"Add my dentist visit on 2024-06-12 from 10:00 to 10:45 as \"Dental Checkup\".\"\n",
      "Skipping (MaxSim 0.815 > 0.8): \"Find when Ramadan ends this year and mark the celebration date.\"\n",
      "Skipping (MaxSim 0.890 > 0.8): \"What's booked on my calendar from tomorrow until Friday?\"\n",
      "Skipping (MaxSim 0.813 > 0.8): \"Look up the Super Bowl 2025 date and create an event to watch it.\"\n",
      "Skipping (MaxSim 0.824 > 0.8): \"Schedule a car maintenance reminder for July 8th at 8 AM lasting 1.5 hours.\"\n",
      "Skipping (MaxSim 0.834 > 0.8): \"Can I see all-day events planned between August 1st and August 10th?\"\n",
      "\n",
      "--- Accepted 0 new diverse query objects this round ---\n",
      "Accepted 0 new diverse query objects in this attempt.\n",
      "Warning: No new diverse queries accepted in this attempt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 25 query objects to diverse_queries_with_scores_v4.json\n",
      "--- End of Turn 3. Total query objects now: 25. Added this turn: 5. ---\n",
      "------------------------------\n",
      "Generation process completed after 3 turns.\n",
      "Total query objects generated or loaded: 25\n",
      "Total new query objects added in this session: 25\n",
      "Final results saved to diverse_queries_with_scores_v4.json\n",
      "\n",
      "Final list of diverse query objects (showing last added marked with '*'):\n",
      "* 1. q: \"Add a meeting titled \"Project Kickoff\" for September 12th from 2:30 PM to 4:00 PM\" (MaxS: 0.000, AvgS: 0.000, TopSim: {})\n",
      "* 2. q: \"Show my calendar events between October 1st and October 7th\" (MaxS: 0.667, AvgS: 0.667, TopSim: 'Add a meeting titled \"Project ...':0.67)\n",
      "* 3. q: \"Find recent news about quantum computing breakthroughs\" (MaxS: 0.788, AvgS: 0.730, TopSim: 'Show my calendar events betwee...':0.79, 'Add a meeting titled \"Project ...':0.67)\n",
      "* 4. q: \"Can you schedule a doctor's appointment on 2024-03-05 at 9:15 AM for 45 minutes?\" (MaxS: 0.729, AvgS: 0.679, TopSim: 'Add a meeting titled \"Project ...':0.73, 'Show my calendar events betwee...':0.68, 'Find recent news about quantum...':0.63)\n",
      "* 5. q: \"Search for top-rated Italian restaurants in Chicago and add a dinner reservation to my calendar\" (MaxS: 0.794, AvgS: 0.747, TopSim: 'Find recent news about quantum...':0.79, 'Show my calendar events betwee...':0.79, 'Add a meeting titled \"Project ...':0.72, 'Can you schedule a doctor's ap...':0.69)\n",
      "* 6. q: \"Create an all-day event called \"Anniversary\" on 2024-05-21\" (MaxS: 0.764, AvgS: 0.657, TopSim: 'Can you schedule a doctor's ap...':0.76, 'Show my calendar events betwee...':0.69, 'Search for top-rated Italian r...':0.66, 'Find recent news about quantum...':0.59, 'Add a meeting titled \"Project ...':0.58)\n",
      "* 7. q: \"What’s my availability like next Wednesday morning?\" (MaxS: 0.792, AvgS: 0.685, TopSim: 'Show my calendar events betwee...':0.79, 'Find recent news about quantum...':0.77, 'Search for top-rated Italian r...':0.73, 'Can you schedule a doctor's ap...':0.62, 'Add a meeting titled \"Project ...':0.61, 'Create an all-day event called...':0.59)\n",
      "* 8. q: \"Display all events from December 20th to December 31st\" (MaxS: 0.748, AvgS: 0.673, TopSim: 'Add a meeting titled \"Project ...':0.75, 'Show my calendar events betwee...':0.69, 'Find recent news about quantum...':0.69, 'Search for top-rated Italian r...':0.67, 'Create an all-day event called...':0.66, 'What’s my availability like ne...':0.63, 'Can you schedule a doctor's ap...':0.61)\n",
      "* 9. q: \"Schedule a dentist appointment for next Thursday from 10:00 AM to 11:30 AM with the summary \"Root Canal Checkup\"\" (MaxS: 0.796, AvgS: 0.725, TopSim: 'Can you schedule a doctor's ap...':0.80, 'Add a meeting titled \"Project ...':0.78, 'Search for top-rated Italian r...':0.77, 'Show my calendar events betwee...':0.71, 'Find recent news about quantum...':0.71, 'Display all events from Decemb...':0.71, 'Create an all-day event called...':0.66, 'What’s my availability like ne...':0.65)\n",
      "* 10. q: \"What's the date range for CES 2025? Create placeholder events spanning those dates with \"Tech Conference\" summaries\" (MaxS: 0.784, AvgS: 0.704, TopSim: 'Search for top-rated Italian r...':0.78, 'Show my calendar events betwee...':0.74, 'Create an all-day event called...':0.73, 'Find recent news about quantum...':0.73, 'What’s my availability like ne...':0.68, 'Can you schedule a doctor's ap...':0.68, 'Schedule a dentist appointment...':0.67, 'Display all events from Decemb...':0.67, 'Add a meeting titled \"Project ...':0.65)\n",
      "* 11. q: \"Search the web for the latest AI conference dates in 2024\" (MaxS: 0.748, AvgS: 0.656, TopSim: 'What's the date range for CES ...':0.75, 'Create an all-day event called...':0.74, 'Search for top-rated Italian r...':0.72, 'Show my calendar events betwee...':0.72, 'Can you schedule a doctor's ap...':0.66, 'Find recent news about quantum...':0.63, 'Schedule a dentist appointment...':0.63, 'Display all events from Decemb...':0.61, 'What’s my availability like ne...':0.58, 'Add a meeting titled \"Project ...':0.53)\n",
      "* 12. q: \"Authorize access to manage my calendar events\" (MaxS: 0.770, AvgS: 0.694, TopSim: 'Find recent news about quantum...':0.77, 'Search for top-rated Italian r...':0.76, 'Show my calendar events betwee...':0.75, 'What's the date range for CES ...':0.73, 'What’s my availability like ne...':0.70, 'Can you schedule a doctor's ap...':0.69, 'Create an all-day event called...':0.68, 'Schedule a dentist appointment...':0.66, 'Display all events from Decemb...':0.66, 'Search the web for the latest ...':0.65)\n",
      "* 13. q: \"Create a marketing team meeting on June 5th, 2024 from 1:30 PM to 2:30 PM\" (MaxS: 0.761, AvgS: 0.661, TopSim: 'What's the date range for CES ...':0.76, 'Add a meeting titled \"Project ...':0.75, 'Display all events from Decemb...':0.71, 'Search for top-rated Italian r...':0.68, 'Create an all-day event called...':0.67, 'Can you schedule a doctor's ap...':0.65, 'Search the web for the latest ...':0.65, 'Schedule a dentist appointment...':0.64, 'Show my calendar events betwee...':0.64, 'Find recent news about quantum...':0.61)\n",
      "* 14. q: \"Show all meetings scheduled during the first week of September 2024\" (MaxS: 0.793, AvgS: 0.745, TopSim: 'What's the date range for CES ...':0.79, 'Search for top-rated Italian r...':0.79, 'Show my calendar events betwee...':0.79, 'Search the web for the latest ...':0.79, 'Find recent news about quantum...':0.79, 'What’s my availability like ne...':0.75, 'Create a marketing team meetin...':0.75, 'Create an all-day event called...':0.72, 'Authorize access to manage my ...':0.72, 'Can you schedule a doctor's ap...':0.72)\n",
      "* 15. q: \"Check my schedule for any conflicts on November 22nd between 3 PM and 5 PM.\" (MaxS: 0.783, AvgS: 0.667, TopSim: 'Add a meeting titled \"Project ...':0.78, 'Search for top-rated Italian r...':0.72, 'Display all events from Decemb...':0.72, 'Show all meetings scheduled du...':0.71, 'Show my calendar events betwee...':0.70, 'Create a marketing team meetin...':0.69, 'Find recent news about quantum...':0.68, 'Schedule a dentist appointment...':0.67, 'What's the date range for CES ...':0.67, 'Can you schedule a doctor's ap...':0.63)\n",
      "* 16. q: \"Search for volunteer opportunities in Austin and block time for Habitat for Humanity on September 21st.\" (MaxS: 0.773, AvgS: 0.719, TopSim: 'Search for top-rated Italian r...':0.77, 'Check my schedule for any conf...':0.76, 'Show all meetings scheduled du...':0.76, 'Show my calendar events betwee...':0.76, 'Display all events from Decemb...':0.75, 'Find recent news about quantum...':0.75, 'What's the date range for CES ...':0.74, 'Schedule a dentist appointment...':0.73, 'Add a meeting titled \"Project ...':0.70, 'What’s my availability like ne...':0.70)\n",
      "* 17. q: \"Can you see if I’m free on December 3rd at 2 PM for a client workshop?\" (MaxS: 0.780, AvgS: 0.715, TopSim: 'Check my schedule for any conf...':0.78, 'Add a meeting titled \"Project ...':0.78, 'Search for top-rated Italian r...':0.77, 'Find recent news about quantum...':0.76, 'Show all meetings scheduled du...':0.76, 'What’s my availability like ne...':0.75, 'Show my calendar events betwee...':0.74, 'Display all events from Decemb...':0.72, 'What's the date range for CES ...':0.72, 'Create a marketing team meetin...':0.71)\n",
      "* 18. q: \"Add a webinar about AI ethics to my schedule on 2024-11-14 from 1:30 PM to 3 PM.\" (MaxS: 0.797, AvgS: 0.694, TopSim: 'Add a meeting titled \"Project ...':0.80, 'Create a marketing team meetin...':0.77, 'Check my schedule for any conf...':0.75, 'Schedule a dentist appointment...':0.74, 'Search for top-rated Italian r...':0.74, 'Can you schedule a doctor's ap...':0.73, 'Show all meetings scheduled du...':0.71, 'Display all events from Decemb...':0.71, 'Can you see if I’m free on Dec...':0.70, 'Search the web for the latest ...':0.69)\n",
      "* 19. q: \"Find the dates for Coachella 2024 and block my calendar with 'Music Festival'\" (MaxS: 0.796, AvgS: 0.704, TopSim: 'What's the date range for CES ...':0.80, 'Show all meetings scheduled du...':0.77, 'Search for top-rated Italian r...':0.76, 'Create an all-day event called...':0.76, 'Authorize access to manage my ...':0.75, 'Create a marketing team meetin...':0.75, 'Search for volunteer opportuni...':0.74, 'Search the web for the latest ...':0.72, 'Find recent news about quantum...':0.71, 'Can you schedule a doctor's ap...':0.71)\n",
      "* 20. q: \"What do I have scheduled on February 14th next year?\" (MaxS: 0.734, AvgS: 0.646, TopSim: 'Schedule a dentist appointment...':0.73, 'Search for top-rated Italian r...':0.71, 'Show my calendar events betwee...':0.71, 'Find recent news about quantum...':0.70, 'What’s my availability like ne...':0.70, 'Add a webinar about AI ethics ...':0.70, 'Search for volunteer opportuni...':0.69, 'Show all meetings scheduled du...':0.68, 'Check my schedule for any conf...':0.67, 'Add a meeting titled \"Project ...':0.65)\n",
      "* 21. q: \"Check if I have any meetings scheduled between March 10th and March 15th.\" (MaxS: 0.799, AvgS: 0.710, TopSim: 'Show all meetings scheduled du...':0.80, 'Search for top-rated Italian r...':0.79, 'Show my calendar events betwee...':0.79, 'What do I have scheduled on Fe...':0.78, 'Check my schedule for any conf...':0.78, 'Find recent news about quantum...':0.76, 'Schedule a dentist appointment...':0.76, 'Can you see if I’m free on Dec...':0.74, 'Add a meeting titled \"Project ...':0.72, 'Add a webinar about AI ethics ...':0.71)\n",
      "* 22. q: \"When does E3 2024 start? Block those three days with \"Gaming Expo\" titles.\" (MaxS: 0.771, AvgS: 0.688, TopSim: 'Find the dates for Coachella 2...':0.77, 'What's the date range for CES ...':0.77, 'Show all meetings scheduled du...':0.76, 'Can you see if I’m free on Dec...':0.76, 'Create a marketing team meetin...':0.74, 'Search for top-rated Italian r...':0.71, 'Show my calendar events betwee...':0.71, 'Create an all-day event called...':0.70, 'Add a meeting titled \"Project ...':0.69, 'Add a webinar about AI ethics ...':0.69)\n",
      "* 23. q: \"What's my schedule look like on June 7th after 1 PM?\" (MaxS: 0.798, AvgS: 0.669, TopSim: 'What’s my availability like ne...':0.80, 'Can you see if I’m free on Dec...':0.78, 'Check if I have any meetings s...':0.76, 'Add a meeting titled \"Project ...':0.74, 'Show my calendar events betwee...':0.74, 'Check my schedule for any conf...':0.73, 'What do I have scheduled on Fe...':0.72, 'Search for top-rated Italian r...':0.72, 'Add a webinar about AI ethics ...':0.71, 'Show all meetings scheduled du...':0.71)\n",
      "* 24. q: \"Do I have any client calls scheduled between May 20th and May 24th?\" (MaxS: 0.772, AvgS: 0.687, TopSim: 'Check if I have any meetings s...':0.77, 'Show my calendar events betwee...':0.75, 'Display all events from Decemb...':0.75, 'Schedule a dentist appointment...':0.73, 'What do I have scheduled on Fe...':0.72, 'Show all meetings scheduled du...':0.70, 'Search for top-rated Italian r...':0.69, 'Can you see if I’m free on Dec...':0.69, 'Find recent news about quantum...':0.69, 'What's the date range for CES ...':0.69)\n",
      "* 25. q: \"Create an all-day event titled 'Anniversary Vacation' on September 14th\" (MaxS: 0.772, AvgS: 0.670, TopSim: 'What do I have scheduled on Fe...':0.77, 'Display all events from Decemb...':0.74, 'Search for volunteer opportuni...':0.74, 'Show my calendar events betwee...':0.73, 'Search for top-rated Italian r...':0.72, 'Schedule a dentist appointment...':0.72, 'Find recent news about quantum...':0.71, 'Check my schedule for any conf...':0.70, 'Check if I have any meetings s...':0.69, 'Add a meeting titled \"Project ...':0.69)\n",
      "\n",
      "--- Placeholder for Step 2: Generating Full Blueprints ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if not model:\n",
    "        print(\"Sentence Transformer model is not loaded. Exiting.\")\n",
    "        exit() # 모델 없이는 실행 불가\n",
    "\n",
    "    # 이전에 승인된 쿼리 객체 로드\n",
    "    accepted_query_objects = load_queries_with_scores(QUERIES_FILENAME)\n",
    "    initial_query_count = len(accepted_query_objects)\n",
    "    # 전체 목표 계산: 초기 개수 + (턴 수 * 턴당 목표 개수)\n",
    "    overall_target = initial_query_count + (NUM_GENERATION_TURNS * QUERIES_TO_GENERATE_PER_TURN)\n",
    "\n",
    "    print(f\"Starting Generation Process.\")\n",
    "    print(f\"Initial query objects loaded: {initial_query_count}\")\n",
    "    print(f\"Targeting {QUERIES_TO_GENERATE_PER_TURN} new queries per turn for {NUM_GENERATION_TURNS} turns.\")\n",
    "    print(f\"Overall target: {overall_target} query objects.\")\n",
    "    print(f\"Using Similarity Threshold (Sentence Transformer): {SIMILARITY_THRESHOLD}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    total_added_this_session = 0\n",
    "\n",
    "    # 지정된 턴 수만큼 반복\n",
    "    for turn in range(1, NUM_GENERATION_TURNS + 1):\n",
    "        print(f\"\\n=== Turn {turn}/{NUM_GENERATION_TURNS} ===\")\n",
    "        target_for_this_turn = QUERIES_TO_GENERATE_PER_TURN # 이번 턴에서 추가할 목표 개수\n",
    "        added_in_this_turn = 0 # 이번 턴에서 실제로 추가된 개수\n",
    "        attempts_this_turn = 0 # 이번 턴에서의 시도 횟수\n",
    "\n",
    "        # LLM 프롬프트에 사용할 현재 쿼리 문자열 목록 (매 턴 시작 시 업데이트)\n",
    "        # 주의: accepted_query_objects가 매우 커지면 이 목록 생성에 시간이 걸릴 수 있음\n",
    "        current_qs_list_for_prompting = [obj['q'] for obj in accepted_query_objects]\n",
    "\n",
    "        # 이번 턴의 목표를 달성하거나 최대 시도 횟수에 도달할 때까지 반복\n",
    "        while added_in_this_turn < target_for_this_turn and attempts_this_turn < MAX_ATTEMPTS_PER_TURN:\n",
    "            attempts_this_turn += 1\n",
    "            print(f\"\\n--- Turn {turn} | Attempt {attempts_this_turn}/{MAX_ATTEMPTS_PER_TURN} ---\")\n",
    "            print(f\"Current total query objects: {len(accepted_query_objects)}\")\n",
    "            print(f\"Goal for this turn: {added_in_this_turn}/{target_for_this_turn} new queries\")\n",
    "\n",
    "            # 이번 시도에서 필요한 쿼리 개수 계산\n",
    "            num_needed_for_turn = target_for_this_turn - added_in_this_turn\n",
    "            # 필요한 개수보다 약간 더 많이 생성 요청 (필터링으로 일부 탈락될 것을 대비)\n",
    "            num_to_generate_this_attempt = min(REQUEST_BATCH_SIZE_PER_TURN, num_needed_for_turn + 5)\n",
    "\n",
    "            # LLM을 사용하여 후보 쿼리 문자열 생성\n",
    "            candidate_qs_strings = generate_candidate_qs_with_llm(\n",
    "                tool_schemas_json,\n",
    "                num_to_generate=num_to_generate_this_attempt,\n",
    "                # LLM에는 현재까지 승인된 쿼리 문자열 목록만 전달\n",
    "                existing_qs_list=current_qs_list_for_prompting,\n",
    "            )\n",
    "\n",
    "            # LLM이 유효한 후보를 반환하지 않은 경우\n",
    "            if not candidate_qs_strings:\n",
    "                print(\"LLM did not return any valid candidate queries or an error occurred. Retrying after delay...\")\n",
    "                time.sleep(5) # 잠시 대기 후 재시도\n",
    "                continue\n",
    "\n",
    "            # *** 변경된 부분: Sentence Transformer 기반 필터링 함수 호출 ***\n",
    "            # 후보 쿼리 필터링 및 점수 계산\n",
    "            # 필터링 함수에는 전체 쿼리 객체 목록과 로드된 모델 전달\n",
    "            new_query_objects = filter_and_score_qs_sentence_transformer(\n",
    "                candidate_qs=candidate_qs_strings,\n",
    "                existing_query_objects=accepted_query_objects, # 비교 대상은 현재까지 승인된 모든 객체\n",
    "                model=model, # 로드된 Sentence Transformer 모델 전달\n",
    "                similarity_threshold=SIMILARITY_THRESHOLD,\n",
    "                top_n_similar=TOP_N_SIMILAR\n",
    "            )\n",
    "            # **********************************************************\n",
    "\n",
    "            # 새로 승인된 쿼리 객체 추가\n",
    "            added_now = 0\n",
    "            for obj in new_query_objects:\n",
    "                # 이번 턴의 목표 개수를 초과하지 않도록 확인\n",
    "                if added_in_this_turn < target_for_this_turn:\n",
    "                    accepted_query_objects.append(obj)\n",
    "                    # 중요: 다음 LLM 호출 및 다음 필터링 시 사용될 목록에도 즉시 반영\n",
    "                    # 이렇게 하면 동일 배치 내에서도 중복/유사성 검사가 더 정확해짐\n",
    "                    current_qs_list_for_prompting.append(obj['q'])\n",
    "                    added_in_this_turn += 1\n",
    "                    added_now += 1\n",
    "                else:\n",
    "                    break # 이번 턴 목표 달성 시 중단\n",
    "\n",
    "            print(f\"Accepted {added_now} new diverse query objects in this attempt.\")\n",
    "\n",
    "            # 두 번째 시도부터는 진행 상황이 없으면 경고 출력\n",
    "            if added_now == 0 and attempts_this_turn > 1:\n",
    "                print(\"Warning: No new diverse queries accepted in this attempt.\")\n",
    "\n",
    "            # 이번 턴의 목표 달성 여부 확인\n",
    "            if added_in_this_turn >= target_for_this_turn:\n",
    "                print(f\"--- Turn {turn} goal reached ({added_in_this_turn} new queries added). ---\")\n",
    "                break # 목표 달성 시 이번 턴의 시도 루프 종료\n",
    "\n",
    "            time.sleep(1) # 시도 사이에 약간의 지연 시간\n",
    "\n",
    "        # 각 턴 종료 시 (목표 달성 또는 최대 시도 도달 시) 업데이트된 목록 저장\n",
    "        total_added_this_session += added_in_this_turn\n",
    "        save_queries_with_scores(accepted_query_objects, QUERIES_FILENAME)\n",
    "        print(f\"--- End of Turn {turn}. Total query objects now: {len(accepted_query_objects)}. Added this turn: {added_in_this_turn}. ---\")\n",
    "\n",
    "\n",
    "    # --- 최종 결과 출력 ---\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Generation process completed after {NUM_GENERATION_TURNS} turns.\")\n",
    "    print(f\"Total query objects generated or loaded: {len(accepted_query_objects)}\")\n",
    "    print(f\"Total new query objects added in this session: {total_added_this_session}\")\n",
    "    print(f\"Final results saved to {QUERIES_FILENAME}\")\n",
    "\n",
    "    print(\"\\nFinal list of diverse query objects (showing last added marked with '*'):\")\n",
    "    # 이번 세션에서 추가된 쿼리 식별 시작 인덱스\n",
    "    start_index = max(0, len(accepted_query_objects) - total_added_this_session)\n",
    "    for i, obj in enumerate(accepted_query_objects):\n",
    "         marker = \"*\" if i >= start_index else \" \" # 이번 세션 추가분 표시\n",
    "         # 결과 객체의 키 이름 확인 (filter_and_score_qs_sentence_transformer 반환값 기준)\n",
    "         similar_dict = obj.get('most_similar_instructions', {}) # 가장 유사한 지시사항 딕셔너리\n",
    "         # 유사도 높은 항목들을 간결하게 표시 (쿼리 앞부분 + 점수)\n",
    "         similar_items = [f\"'{q[:30]}...':{s:.2f}\" for q, s in similar_dict.items()]\n",
    "         similar_str = \", \".join(similar_items) if similar_items else \"{}\" # 비어있으면 {} 표시\n",
    "\n",
    "         # 최대 및 평균 유사도 점수 가져오기\n",
    "         max_sim_score = obj.get('max_similarity_score_against_all', 0)\n",
    "         avg_sim_score = obj.get('avg_similarity_score', 0)\n",
    "\n",
    "         # 최종 출력 형식\n",
    "         print(f\"{marker} {i+1}. q: \\\"{obj['q']}\\\" (MaxS: {max_sim_score:.3f}, AvgS: {avg_sim_score:.3f}, TopSim: {similar_str})\")\n",
    "\n",
    "\n",
    "    # --- Placeholder for Step 2 (Generating Full Blueprints) ---\n",
    "    print(\"\\n--- Placeholder for Step 2: Generating Full Blueprints ---\")\n",
    "    # 이제 accepted_query_objects 리스트를 순회하며 각 'q' 필드를 사용하여\n",
    "    # 전체 블루프린트를 생성하는 로직을 구현할 수 있습니다.\n",
    "    # 예시:\n",
    "    # final_blueprints = []\n",
    "    # for query_obj in accepted_query_objects:\n",
    "    #     q_final = query_obj['q']\n",
    "    #     # blueprint_dict = generate_full_blueprint_for_q(q_final, tool_schemas_json, client)\n",
    "    #     # if blueprint_dict: final_blueprints.append(blueprint_dict)\n",
    "    # print(f\"\\n--- Generated {len(final_blueprints)} full Blueprints ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec264291",
   "metadata": {},
   "source": [
    "for print the queries from the JSON file `diverse_queries_with_scores_v4.json`, you can use the following command:\n",
    "\n",
    "```shell\n",
    "jq -r '.[] | .q' diverse_queries_with_scores_v4.json\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
