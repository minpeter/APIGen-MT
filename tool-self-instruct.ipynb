{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional, Annotated, Callable, Tuple\n",
    "from difflib import SequenceMatcher # Option 1 for basic similarity\n",
    "import heapq # For finding top N similar items efficiently\n",
    "import numpy as np # For calculating mean similarity\n",
    "from rouge_score import rouge_scorer\n",
    "from openai import OpenAI, APIError\n",
    "from function_schema import get_function_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787e83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Friendli AI Client Setup ---\n",
    "token = os.getenv(\"FRIENDLI_TOKEN\")\n",
    "if not token:\n",
    "    print(\"Error: FRIENDLI_TOKEN environment variable not set.\")\n",
    "    print(\"Please set the environment variable or replace '<YOUR_FRIENDLI_TOKEN>' in the code.\")\n",
    "    token = \"<YOUR_FRIENDLI_TOKEN>\" # Placeholder\n",
    "\n",
    "if token == \"<YOUR_FRIENDLI_TOKEN>\":\n",
    "     print(\"Warning: Using placeholder Friendli token. LLM calls will likely fail.\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"https://api.friendli.ai/serverless/v1\",\n",
    "    api_key = token\n",
    ")\n",
    "LLM_MODEL_NAME = \"deepseek-r1\" # Specify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(\n",
    "    city: Annotated[str, \"The city to get the weather for\"],\n",
    "    unit: Annotated[Optional[str], \"The unit to return the temperature in\"] = \"celcius\",\n",
    ") -> str:\n",
    "    \"\"\"Returns the weather for the given city.\"\"\"\n",
    "    return f\"Weather for {city} is 20°C\"\n",
    "\n",
    "def get_news(\n",
    "    topic: Annotated[str, \"The topic to get news for\"],\n",
    "    source: Annotated[Optional[str], \"The source to get news from\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Returns the news for the given topic.\"\"\"\n",
    "    return f\"News for {topic} from {source if source else 'all sources'}\"\n",
    "\n",
    "def get_current_location() -> str:\n",
    "    \"\"\"Returns the current location of the user.\"\"\"\n",
    "    return \"Current location is Seoul, South Korea\"\n",
    "\n",
    "tools = [\n",
    "    get_weather,\n",
    "    get_news,\n",
    "    get_current_location,\n",
    "]\n",
    "\n",
    "tool_schemas = [get_function_schema(tool) for tool in tools]\n",
    "tool_schemas_json = json.dumps(tool_schemas, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfced6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "QUERIES_FILENAME = \"diverse_queries_with_scores_v4.json\" # New filename for this version\n",
    "NUM_GENERATION_TURNS = 3\n",
    "QUERIES_TO_GENERATE_PER_TURN = 10\n",
    "REQUEST_BATCH_SIZE_PER_TURN = 15\n",
    "MAX_ATTEMPTS_PER_TURN = 5\n",
    "SIMILARITY_THRESHOLD = 0.8\n",
    "TOP_N_SIMILAR = 10 # Alpaca stores top 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_queries_with_scores(filename: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Loads previously generated query objects from a JSON file.\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, list) and all(isinstance(item, dict) and 'q' in item for item in data):\n",
    "                    print(f\"Loaded {len(data)} query objects from {filename}\")\n",
    "                    return data\n",
    "                else:\n",
    "                    print(f\"Warning: Invalid format found in {filename}. Starting fresh.\")\n",
    "                    return []\n",
    "        except (json.JSONDecodeError, IOError) as e:\n",
    "            print(f\"Error loading {filename}: {e}. Starting fresh.\")\n",
    "            return []\n",
    "    else:\n",
    "        print(f\"No existing query file found ({filename}). Starting fresh.\")\n",
    "        return []\n",
    "\n",
    "def save_queries_with_scores(query_objects: List[Dict[str, Any]], filename: str):\n",
    "    \"\"\"Saves the list of query objects to a JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            # Use indent=4 like Alpaca's output\n",
    "            json.dump(query_objects, f, indent=4, ensure_ascii=False)\n",
    "        print(f\"Saved {len(query_objects)} query objects to {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error saving queries to {filename}: {e}\")\n",
    "\n",
    "def is_valid_query_line(q_text: str) -> bool:\n",
    "    \"\"\"Checks if a single line looks like a valid user query.\"\"\"\n",
    "    q_text = q_text.strip()\n",
    "    if not q_text: return False\n",
    "    # More robust filtering based on common LLM reasoning/meta-commentary patterns\n",
    "    if q_text.startswith((\"- \", \"* \", \"Okay,\", \"First,\", \"Next,\", \"Now,\", \"Let me\", \"Wait,\", \"Also,\", \"###\", \"//\", \"```\", \"Queries\", \"That's\", \"This should\", \"Avoid\", \"Check for\", \"Example\", \"User Query:\", \"Generated Query:\")): return False\n",
    "    if q_text.endswith(\":\") or \"→\" in q_text: return False\n",
    "    if re.match(r\"^\\d+\\.\", q_text): return False\n",
    "    if len(q_text.split()) <= 1 and not re.search(r'[a-zA-Z]', q_text): return False\n",
    "    if \"/\" in q_text and \".\" in q_text and \" \" not in q_text: return False\n",
    "    # Filter lines that are likely descriptions of tools or parameters\n",
    "    if any(tool_name in q_text.lower() for tool_name in [\"get_weather\", \"get_news\", \"get_current_location\"]):\n",
    "        if \"parameter\" in q_text.lower() or \"require\" in q_text.lower() or \"tool\" in q_text.lower():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def remove_think_blocks(text: str) -> str:\n",
    "    \"\"\"Removes <think>...</think> blocks from the text.\"\"\"\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL | re.IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ea68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 1: Generate Diverse User Queries ('q') ---\n",
    "\n",
    "def generate_candidate_qs_with_llm(\n",
    "    tool_schemas_str: str,\n",
    "    num_to_generate: int,\n",
    "    existing_qs_list: List[str],\n",
    ") -> List[str]:\n",
    "    \"\"\"Generates candidate 'q' strings using the LLM, removing think blocks.\"\"\"\n",
    "    \n",
    "    system_prompt = f\"\"\"Your ONLY task is to generate realistic, diverse user queries or requests ('q') suitable for an AI assistant with access to specific tools. These queries should be answerable using the provided tools. Vary the complexity, phrasing (questions, commands), and the tools potentially required.\n",
    "\n",
    "**CRITICAL INSTRUCTIONS:**\n",
    "1.  Output ONLY the raw user queries.\n",
    "2.  Each query MUST be on a new line.\n",
    "3.  **ABSOLUTELY DO NOT** include:\n",
    "    * Explanations, comments, or justifications.\n",
    "    * Thinking processes, reasoning steps (including anything like `<think>...</think>`).\n",
    "    * Numbered lists, bullet points, or any formatting other than one query per line.\n",
    "    * Any text before the first query or after the last query.\n",
    "\"\"\"\n",
    "\n",
    "    examples_prompt = \"\"\n",
    "    if existing_qs_list:\n",
    "        sample_existing = random.sample(existing_qs_list, min(len(existing_qs_list), 5))\n",
    "        examples_prompt = \"Critically, avoid generating queries too similar to these examples:\\n- \" + \"\\n- \".join(sample_existing) + \"\\n\\n\"\n",
    "\n",
    "    user_prompt = f\"\"\"Based on the following available tools: {tool_schemas_str}\n",
    "Generate exactly {num_to_generate} diverse user queries ('q'). Remember to vary the required tools, complexity, and phrasing. {examples_prompt}Output ONLY the queries, one per line:\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    try:\n",
    "        print(f\"--- Calling LLM ({LLM_MODEL_NAME}) to generate ~{num_to_generate} queries ---\")\n",
    "        completion = client.chat.completions.create(\n",
    "            model=LLM_MODEL_NAME, messages=messages, temperature=0.8, max_tokens=4096,\n",
    "        )\n",
    "        raw_llm_output = completion.choices[0].message.content\n",
    "        print(\"--- LLM Response Received ---\")\n",
    "    except APIError as e:\n",
    "        print(f\"LLM API Error: {e}\"); return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during LLM call: {e}\"); return []\n",
    "    cleaned_output = remove_think_blocks(raw_llm_output)\n",
    "    candidate_qs = []\n",
    "    raw_lines = cleaned_output.split('\\n')\n",
    "    print(f\"--- Lines after removing <think> blocks: {len(raw_lines)} ---\") # Debugging\n",
    "    for line in raw_lines:\n",
    "        clean_line = line.strip()\n",
    "        if is_valid_query_line(clean_line):\n",
    "            candidate_qs.append(clean_line)\n",
    "        elif clean_line:\n",
    "             print(f\"Filtered out invalid line: '{clean_line}'\")\n",
    "\n",
    "    print(f\"--- Parsed {len(candidate_qs)} potentially valid candidate queries ---\")\n",
    "    return candidate_qs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8100ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_qs_strings = generate_candidate_qs_with_llm(\n",
    "    tool_schemas_json,\n",
    "    num_to_generate=5,\n",
    "    existing_qs_list=[],\n",
    ")\n",
    "\n",
    "print(candidate_qs_strings) # Debugging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e32ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치: pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch # sentence-transformers가 내부적으로 사용\n",
    "\n",
    "# 한국어 사전 훈련 모델 로드 (다양한 모델 사용 가능)\n",
    "# 예시: 'jhgan/ko-sbert-sts', 'snunlp/KR-SBERT-V40K-klueNLI-augSTS' 등\n",
    "# 모델 목록: https://huggingface.co/models?language=ko&library=sentence-transformers\n",
    "print(\"Loading Korean Sentence Transformer model...\")\n",
    "# model = SentenceTransformer('jhgan/ko-sbert-sts')\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# 비교할 텍스트\n",
    "references_ko = [\n",
    "    \"The cat was found under the bed\",\n",
    "    \"The cat was under the bed\"\n",
    "]\n",
    "candidate_ko = \"The cat likes to eat Churu\"\n",
    "\n",
    "# 문장 임베딩 계산\n",
    "# 참고: GPU 사용 가능 시 자동으로 활용하여 속도 향상\n",
    "print(\"Encoding sentences...\")\n",
    "ref_embeddings = model.encode(references_ko, convert_to_tensor=True)\n",
    "cand_embedding = model.encode(candidate_ko, convert_to_tensor=True)\n",
    "print(\"Encoding complete.\")\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "# 후보 문장과 각 참조 문장 간의 유사도 계산\n",
    "cosine_scores = util.pytorch_cos_sim(cand_embedding, ref_embeddings)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n--- Sentence Embedding Cosine Similarity ---\")\n",
    "for i, score in enumerate(cosine_scores[0]): # cand_embedding은 하나이므로 [0] 인덱스 사용\n",
    "    print(f\"Candidate vs Reference {i+1}: {score.item():.4f}\")\n",
    "\n",
    "# 여러 참조 문장 중 가장 높은 유사도 선택\n",
    "max_similarity = torch.max(cosine_scores[0]).item()\n",
    "print(f\"\\nMaximum Similarity Score: {max_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d84c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/minpeter/.anaconda3/envs/py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import heapq # top_n_similar 계산을 위해 유지\n",
    "\n",
    "# --- 모델 로딩 (애플리케이션 시작 시 한 번 수행하는 것이 이상적) ---\n",
    "# 한국어 사전 훈련 모델 로드\n",
    "# 사용 가능한 모델 예시: 'jhgan/ko-sbert-sts', 'snunlp/KR-SBERT-V40K-klueNLI-augSTS' 등\n",
    "print(\"Loading Korean Sentence Transformer model...\")\n",
    "# model_name = 'jhgan/ko-sbert-sts'\n",
    "model_name = 'snunlp/KR-SBERT-V40K-klueNLI-augSTS'\n",
    "try:\n",
    "    # GPU 사용 가능 시 자동으로 활용\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print(f\"Model '{model_name}' loaded successfully.\")\n",
    "    # 모델을 GPU로 이동 (사용 가능한 경우)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(torch.device(\"cuda\"))\n",
    "        print(\"Model moved to GPU.\")\n",
    "    else:\n",
    "        print(\"GPU not available, using CPU.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Sentence Transformer model: {e}\")\n",
    "    model = None # 모델 로딩 실패 시 None으로 설정\n",
    "\n",
    "# --- 개선된 필터링 함수 ---\n",
    "def filter_and_score_qs_sentence_transformer(\n",
    "    candidate_qs: List[str],\n",
    "    existing_query_objects: List[Dict[str, Any]],\n",
    "    model: SentenceTransformer, # 로드된 모델을 인자로 받음\n",
    "    similarity_threshold: float = 0.8,\n",
    "    top_n_similar: int = 10\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Filters candidate questions based on maximum semantic similarity using Sentence Transformers\n",
    "    and scores the accepted ones.\n",
    "\n",
    "    Args:\n",
    "        candidate_qs: List of new candidate question strings.\n",
    "        existing_query_objects: List of dictionaries, each representing an existing query\n",
    "                                (must contain at least a 'q' key with the query string).\n",
    "        model: The pre-loaded Sentence Transformer model.\n",
    "        similarity_threshold: The maximum similarity score allowed for a candidate to be accepted.\n",
    "        top_n_similar: The number of most similar existing questions to record for accepted candidates.\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries, each representing an accepted new query with similarity scores.\n",
    "    \"\"\"\n",
    "    if not model:\n",
    "        print(\"Error: Sentence Transformer model is not loaded. Cannot perform filtering.\")\n",
    "        return []\n",
    "\n",
    "    if not candidate_qs:\n",
    "        print(\"No candidate questions provided.\")\n",
    "        return []\n",
    "\n",
    "    newly_accepted_query_objects = []\n",
    "    existing_qs_list = [obj['q'] for obj in existing_query_objects]\n",
    "\n",
    "    # --- 임베딩 계산 ---\n",
    "    # 기존 질문 임베딩 (비어있지 않은 경우에만 계산)\n",
    "    existing_embeddings = None\n",
    "    if existing_qs_list:\n",
    "        print(f\"Encoding {len(existing_qs_list)} existing queries...\")\n",
    "        # 배치 처리 및 GPU 활용 (모델이 GPU에 있다면)\n",
    "        existing_embeddings = model.encode(existing_qs_list, convert_to_tensor=True, show_progress_bar=True)\n",
    "        print(\"Existing queries encoded.\")\n",
    "\n",
    "    # 후보 질문 임베딩\n",
    "    print(f\"Encoding {len(candidate_qs)} candidate queries...\")\n",
    "    candidate_embeddings = model.encode(candidate_qs, convert_to_tensor=True, show_progress_bar=True)\n",
    "    print(\"Candidate queries encoded.\")\n",
    "\n",
    "    # 비교 대상 질문 목록 및 임베딩 (반복문 내에서 업데이트됨)\n",
    "    # 초기에는 기존 질문들로 설정\n",
    "    all_qs_strings_for_comparison = list(existing_qs_list)\n",
    "    # .clone()을 사용하여 원본 existing_embeddings가 변경되지 않도록 함\n",
    "    all_embeddings_for_comparison = existing_embeddings.clone() if existing_embeddings is not None else None\n",
    "\n",
    "    print(f\"\\n--- Filtering {len(candidate_qs)} candidates for diversity against {len(all_qs_strings_for_comparison)} existing/accepted queries ---\")\n",
    "\n",
    "    # 후보 질문들을 순회하며 필터링\n",
    "    for i, q_new in enumerate(candidate_qs):\n",
    "        q_new_lower = q_new.lower()\n",
    "        cand_embedding = candidate_embeddings[i] # 해당 후보의 미리 계산된 임베딩 사용\n",
    "\n",
    "        # 1. 정확히 동일한 질문인지 확인 (소문자 기준)\n",
    "        is_exact_duplicate = any(q_new_lower == q_old.lower() for q_old in all_qs_strings_for_comparison)\n",
    "        if is_exact_duplicate:\n",
    "            # print(f\"Skipping exact duplicate: \\\"{q_new}\\\"\") # 로그 출력 필요 시 주석 해제\n",
    "            continue\n",
    "\n",
    "        # 2. 기존/수락된 질문들과의 유사도 계산\n",
    "        max_similarity = 0.0\n",
    "        avg_similarity = 0.0\n",
    "        similarities_list = [] # (score, query) 튜플 저장 리스트\n",
    "\n",
    "        # 비교 대상 임베딩이 있는 경우에만 유사도 계산\n",
    "        if all_embeddings_for_comparison is not None and all_embeddings_for_comparison.shape[0] > 0:\n",
    "            # 코사인 유사도 계산 (후보 1개 vs 모든 비교 대상)\n",
    "            # cand_embedding 차원을 [1, embedding_dim]으로 맞춰줌\n",
    "            cosine_scores = util.pytorch_cos_sim(cand_embedding.unsqueeze(0), all_embeddings_for_comparison)[0] # 결과는 tensor([score1, score2, ...])\n",
    "\n",
    "            # CPU로 이동 후 numpy 배열로 변환하여 사용 (GPU 메모리 절약 및 호환성)\n",
    "            cosine_scores_cpu = cosine_scores.cpu().numpy()\n",
    "\n",
    "            if cosine_scores_cpu.size > 0: # 유사도 점수가 계산된 경우\n",
    "                max_similarity = np.max(cosine_scores_cpu)\n",
    "                avg_similarity = np.mean(cosine_scores_cpu)\n",
    "                # 유사도 점수와 해당 질문 텍스트를 묶어서 리스트 생성\n",
    "                similarities_list = list(zip(cosine_scores_cpu, all_qs_strings_for_comparison))\n",
    "            else: # 비교 대상은 있으나 어떤 이유로든 점수 계산이 안된 경우 (이론상 발생하기 어려움)\n",
    "                max_similarity = 0.0\n",
    "                avg_similarity = 0.0\n",
    "                similarities_list = []\n",
    "\n",
    "        # 3. Alpaca 스타일 필터링: 최대 유사도가 임계값보다 높으면 건너뛰기\n",
    "        if max_similarity > similarity_threshold:\n",
    "            print(f\"Skipping (MaxSim {max_similarity:.3f} > {similarity_threshold}): \\\"{q_new}\\\"\")\n",
    "            continue\n",
    "\n",
    "        # 4. 필터를 통과한 경우: 결과 저장 및 다음 비교를 위해 추가\n",
    "        print(f\"Accepting (MaxSim {max_similarity:.3f} <= {similarity_threshold}): \\\"{q_new}\\\"\")\n",
    "\n",
    "        # 가장 유사한 N개 찾기 (heapq 사용)\n",
    "        most_similar_dict = {}\n",
    "        if similarities_list:\n",
    "            # 실제 top_n 개수는 유사도 리스트 크기와 top_n_similar 중 작은 값\n",
    "            actual_top_n = min(top_n_similar, len(similarities_list))\n",
    "            # 점수가 높은 순서대로 정렬 (튜플의 첫 번째 요소인 점수 기준)\n",
    "            top_n = heapq.nlargest(actual_top_n, similarities_list, key=lambda item: item[0])\n",
    "            # 딕셔너리로 변환 (소수점 4자리까지 반올림, 0.01 이하 점수는 제외)\n",
    "            most_similar_dict = {q: round(float(score), 4) for score, q in top_n if float(score) > 0.01}\n",
    "\n",
    "\n",
    "        # 새로운 질문 객체 생성\n",
    "        new_obj = {\n",
    "            \"q\": q_new,\n",
    "            \"max_similarity_score_against_all\": round(float(max_similarity), 4), # float로 변환\n",
    "            \"avg_similarity_score\": round(float(avg_similarity), 4), # float로 변환\n",
    "            \"most_similar_instructions\": most_similar_dict # 기존 키 이름 유지\n",
    "        }\n",
    "        newly_accepted_query_objects.append(new_obj)\n",
    "\n",
    "        # 다음 후보 비교를 위해 현재 수락된 질문과 임베딩을 비교 대상 목록에 추가\n",
    "        all_qs_strings_for_comparison.append(q_new)\n",
    "        # 임베딩 추가: all_embeddings_for_comparison이 None이면 새로 생성, 아니면 이어붙임\n",
    "        cand_embedding_expanded = cand_embedding.unsqueeze(0) # 차원 맞추기 [1, embedding_dim]\n",
    "        if all_embeddings_for_comparison is None:\n",
    "            all_embeddings_for_comparison = cand_embedding_expanded\n",
    "        else:\n",
    "            all_embeddings_for_comparison = torch.cat((all_embeddings_for_comparison, cand_embedding_expanded), dim=0)\n",
    "\n",
    "    print(f\"\\n--- Accepted {len(newly_accepted_query_objects)} new diverse query objects this round ---\")\n",
    "    return newly_accepted_query_objects\n",
    "\n",
    "# --- 예시 사용법 ---\n",
    "if __name__ == \"__main__\":\n",
    "    if model: # 모델이 성공적으로 로드되었을 때만 실행\n",
    "        # 기존에 존재하는 질문들 (예시)\n",
    "        existing_queries = [\n",
    "            {\"q\": \"오늘 날씨 어때?\", \"other_data\": 1},\n",
    "            {\"q\": \"서울 맛집 추천해줘\", \"other_data\": 2},\n",
    "            {\"q\": \"파이썬으로 웹사이트 만드는 법 알려줘\", \"other_data\": 3}\n",
    "        ]\n",
    "\n",
    "        # 새로 들어온 후보 질문들 (예시)\n",
    "        candidate_queries = [\n",
    "            \"오늘 서울 날씨 알려줄래?\", # 기존 질문과 유사\n",
    "            \"제주도 가볼만한 곳\",\n",
    "            \"파이썬 웹 개발 방법\", # 기존 질문과 유사\n",
    "            \"점심 메뉴 추천\",\n",
    "            \"오늘 날씨 어때?\" # 기존 질문과 정확히 일치\n",
    "        ]\n",
    "\n",
    "        # 필터링 및 스코어링 실행\n",
    "        accepted_queries = filter_and_score_qs_sentence_transformer(\n",
    "            candidate_qs=candidate_queries,\n",
    "            existing_query_objects=existing_queries,\n",
    "            model=model,\n",
    "            similarity_threshold=0.8, # 유사도 임계값 (조정 가능)\n",
    "            top_n_similar=3\n",
    "        )\n",
    "\n",
    "        print(\"\\n--- Accepted Queries ---\")\n",
    "        for i, query_obj in enumerate(accepted_queries):\n",
    "            print(f\"{i+1}. Query: \\\"{query_obj['q']}\\\"\")\n",
    "            print(f\"   Max Similarity: {query_obj['max_similarity_score_against_all']:.4f}\")\n",
    "            print(f\"   Avg Similarity: {query_obj['avg_similarity_score']:.4f}\")\n",
    "            print(f\"   Most Similar ({len(query_obj['most_similar_instructions'])}): {query_obj['most_similar_instructions']}\")\n",
    "            print(\"-\" * 20)\n",
    "    else:\n",
    "        print(\"Skipping example usage because the model could not be loaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91003c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if not model:\n",
    "        print(\"Sentence Transformer model is not loaded. Exiting.\")\n",
    "        exit() # 모델 없이는 실행 불가\n",
    "\n",
    "    # 이전에 승인된 쿼리 객체 로드\n",
    "    accepted_query_objects = load_queries_with_scores(QUERIES_FILENAME)\n",
    "    initial_query_count = len(accepted_query_objects)\n",
    "    # 전체 목표 계산: 초기 개수 + (턴 수 * 턴당 목표 개수)\n",
    "    overall_target = initial_query_count + (NUM_GENERATION_TURNS * QUERIES_TO_GENERATE_PER_TURN)\n",
    "\n",
    "    print(f\"Starting Generation Process.\")\n",
    "    print(f\"Initial query objects loaded: {initial_query_count}\")\n",
    "    print(f\"Targeting {QUERIES_TO_GENERATE_PER_TURN} new queries per turn for {NUM_GENERATION_TURNS} turns.\")\n",
    "    print(f\"Overall target: {overall_target} query objects.\")\n",
    "    print(f\"Using Similarity Threshold (Sentence Transformer): {SIMILARITY_THRESHOLD}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    total_added_this_session = 0\n",
    "\n",
    "    # 지정된 턴 수만큼 반복\n",
    "    for turn in range(1, NUM_GENERATION_TURNS + 1):\n",
    "        print(f\"\\n=== Turn {turn}/{NUM_GENERATION_TURNS} ===\")\n",
    "        target_for_this_turn = QUERIES_TO_GENERATE_PER_TURN # 이번 턴에서 추가할 목표 개수\n",
    "        added_in_this_turn = 0 # 이번 턴에서 실제로 추가된 개수\n",
    "        attempts_this_turn = 0 # 이번 턴에서의 시도 횟수\n",
    "\n",
    "        # LLM 프롬프트에 사용할 현재 쿼리 문자열 목록 (매 턴 시작 시 업데이트)\n",
    "        # 주의: accepted_query_objects가 매우 커지면 이 목록 생성에 시간이 걸릴 수 있음\n",
    "        current_qs_list_for_prompting = [obj['q'] for obj in accepted_query_objects]\n",
    "\n",
    "        # 이번 턴의 목표를 달성하거나 최대 시도 횟수에 도달할 때까지 반복\n",
    "        while added_in_this_turn < target_for_this_turn and attempts_this_turn < MAX_ATTEMPTS_PER_TURN:\n",
    "            attempts_this_turn += 1\n",
    "            print(f\"\\n--- Turn {turn} | Attempt {attempts_this_turn}/{MAX_ATTEMPTS_PER_TURN} ---\")\n",
    "            print(f\"Current total query objects: {len(accepted_query_objects)}\")\n",
    "            print(f\"Goal for this turn: {added_in_this_turn}/{target_for_this_turn} new queries\")\n",
    "\n",
    "            # 이번 시도에서 필요한 쿼리 개수 계산\n",
    "            num_needed_for_turn = target_for_this_turn - added_in_this_turn\n",
    "            # 필요한 개수보다 약간 더 많이 생성 요청 (필터링으로 일부 탈락될 것을 대비)\n",
    "            num_to_generate_this_attempt = min(REQUEST_BATCH_SIZE_PER_TURN, num_needed_for_turn + 5)\n",
    "\n",
    "            # LLM을 사용하여 후보 쿼리 문자열 생성\n",
    "            candidate_qs_strings = generate_candidate_qs_with_llm(\n",
    "                tool_schemas_json,\n",
    "                num_to_generate=num_to_generate_this_attempt,\n",
    "                # LLM에는 현재까지 승인된 쿼리 문자열 목록만 전달\n",
    "                existing_qs_list=current_qs_list_for_prompting,\n",
    "            )\n",
    "\n",
    "            # LLM이 유효한 후보를 반환하지 않은 경우\n",
    "            if not candidate_qs_strings:\n",
    "                print(\"LLM did not return any valid candidate queries or an error occurred. Retrying after delay...\")\n",
    "                time.sleep(5) # 잠시 대기 후 재시도\n",
    "                continue\n",
    "\n",
    "            # *** 변경된 부분: Sentence Transformer 기반 필터링 함수 호출 ***\n",
    "            # 후보 쿼리 필터링 및 점수 계산\n",
    "            # 필터링 함수에는 전체 쿼리 객체 목록과 로드된 모델 전달\n",
    "            new_query_objects = filter_and_score_qs_sentence_transformer(\n",
    "                candidate_qs=candidate_qs_strings,\n",
    "                existing_query_objects=accepted_query_objects, # 비교 대상은 현재까지 승인된 모든 객체\n",
    "                model=model, # 로드된 Sentence Transformer 모델 전달\n",
    "                similarity_threshold=SIMILARITY_THRESHOLD,\n",
    "                top_n_similar=TOP_N_SIMILAR\n",
    "            )\n",
    "            # **********************************************************\n",
    "\n",
    "            # 새로 승인된 쿼리 객체 추가\n",
    "            added_now = 0\n",
    "            for obj in new_query_objects:\n",
    "                # 이번 턴의 목표 개수를 초과하지 않도록 확인\n",
    "                if added_in_this_turn < target_for_this_turn:\n",
    "                    accepted_query_objects.append(obj)\n",
    "                    # 중요: 다음 LLM 호출 및 다음 필터링 시 사용될 목록에도 즉시 반영\n",
    "                    # 이렇게 하면 동일 배치 내에서도 중복/유사성 검사가 더 정확해짐\n",
    "                    current_qs_list_for_prompting.append(obj['q'])\n",
    "                    added_in_this_turn += 1\n",
    "                    added_now += 1\n",
    "                else:\n",
    "                    break # 이번 턴 목표 달성 시 중단\n",
    "\n",
    "            print(f\"Accepted {added_now} new diverse query objects in this attempt.\")\n",
    "\n",
    "            # 두 번째 시도부터는 진행 상황이 없으면 경고 출력\n",
    "            if added_now == 0 and attempts_this_turn > 1:\n",
    "                print(\"Warning: No new diverse queries accepted in this attempt.\")\n",
    "\n",
    "            # 이번 턴의 목표 달성 여부 확인\n",
    "            if added_in_this_turn >= target_for_this_turn:\n",
    "                print(f\"--- Turn {turn} goal reached ({added_in_this_turn} new queries added). ---\")\n",
    "                break # 목표 달성 시 이번 턴의 시도 루프 종료\n",
    "\n",
    "            time.sleep(1) # 시도 사이에 약간의 지연 시간\n",
    "\n",
    "        # 각 턴 종료 시 (목표 달성 또는 최대 시도 도달 시) 업데이트된 목록 저장\n",
    "        total_added_this_session += added_in_this_turn\n",
    "        save_queries_with_scores(accepted_query_objects, QUERIES_FILENAME)\n",
    "        print(f\"--- End of Turn {turn}. Total query objects now: {len(accepted_query_objects)}. Added this turn: {added_in_this_turn}. ---\")\n",
    "\n",
    "\n",
    "    # --- 최종 결과 출력 ---\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Generation process completed after {NUM_GENERATION_TURNS} turns.\")\n",
    "    print(f\"Total query objects generated or loaded: {len(accepted_query_objects)}\")\n",
    "    print(f\"Total new query objects added in this session: {total_added_this_session}\")\n",
    "    print(f\"Final results saved to {QUERIES_FILENAME}\")\n",
    "\n",
    "    print(\"\\nFinal list of diverse query objects (showing last added marked with '*'):\")\n",
    "    # 이번 세션에서 추가된 쿼리 식별 시작 인덱스\n",
    "    start_index = max(0, len(accepted_query_objects) - total_added_this_session)\n",
    "    for i, obj in enumerate(accepted_query_objects):\n",
    "         marker = \"*\" if i >= start_index else \" \" # 이번 세션 추가분 표시\n",
    "         # 결과 객체의 키 이름 확인 (filter_and_score_qs_sentence_transformer 반환값 기준)\n",
    "         similar_dict = obj.get('most_similar_instructions', {}) # 가장 유사한 지시사항 딕셔너리\n",
    "         # 유사도 높은 항목들을 간결하게 표시 (쿼리 앞부분 + 점수)\n",
    "         similar_items = [f\"'{q[:30]}...':{s:.2f}\" for q, s in similar_dict.items()]\n",
    "         similar_str = \", \".join(similar_items) if similar_items else \"{}\" # 비어있으면 {} 표시\n",
    "\n",
    "         # 최대 및 평균 유사도 점수 가져오기\n",
    "         max_sim_score = obj.get('max_similarity_score_against_all', 0)\n",
    "         avg_sim_score = obj.get('avg_similarity_score', 0)\n",
    "\n",
    "         # 최종 출력 형식\n",
    "         print(f\"{marker} {i+1}. q: \\\"{obj['q']}\\\" (MaxS: {max_sim_score:.3f}, AvgS: {avg_sim_score:.3f}, TopSim: {similar_str})\")\n",
    "\n",
    "\n",
    "    # --- Placeholder for Step 2 (Generating Full Blueprints) ---\n",
    "    print(\"\\n--- Placeholder for Step 2: Generating Full Blueprints ---\")\n",
    "    # 이제 accepted_query_objects 리스트를 순회하며 각 'q' 필드를 사용하여\n",
    "    # 전체 블루프린트를 생성하는 로직을 구현할 수 있습니다.\n",
    "    # 예시:\n",
    "    # final_blueprints = []\n",
    "    # for query_obj in accepted_query_objects:\n",
    "    #     q_final = query_obj['q']\n",
    "    #     # blueprint_dict = generate_full_blueprint_for_q(q_final, tool_schemas_json, client)\n",
    "    #     # if blueprint_dict: final_blueprints.append(blueprint_dict)\n",
    "    # print(f\"\\n--- Generated {len(final_blueprints)} full Blueprints ---\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
